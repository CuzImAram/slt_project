<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/SourceRetriever.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/SourceRetriever.py" />
              <option name="originalContent" value="import pandas as pd&#10;from dotenv import dotenv_values&#10;from elasticsearch import Elasticsearch&#10;&#10;# --- Adjust Pandas display options ---&#10;# Ensures that the entire text in the columns is displayed.&#10;pd.set_option('display.max_colwidth', None)&#10;# Ensures that all columns are displayed.&#10;pd.set_option('display.max_columns', None)&#10;# Ensures that the output optimally uses the console width.&#10;pd.set_option('display.width', None)&#10;&#10;&#10;# --- Configuration ---&#10;# Loads environment variables from the .env file.&#10;# Make sure your .env file contains the ES_API_KEY.&#10;config = dotenv_values(&quot;.env&quot;)&#10;ES_API_KEY = config.get(&quot;ES_API_KEY&quot;)&#10;&#10;# Connection parameters from your provided notebook.&#10;ES_HOST = &quot;https://elasticsearch.bw.webis.de:9200&quot;&#10;INDEX_NAME_SERPS = &quot;aql_serps&quot;&#10;INDEX_NAME_RESULTS = &quot;aql_results&quot;&#10;&#10;class SourceRetriever:&#10;    &quot;&quot;&quot;&#10;    A class for retrieving sources from Elasticsearch using advanced queries&#10;    and Pandas for data manipulation. This version uses an instance client for ES.&#10;    &quot;&quot;&quot;&#10;&#10;    def __init__(self, host: str, api_key: str, serps_index: str, results_index: str):&#10;        &quot;&quot;&quot;&#10;        Initializes the retriever and establishes the connection to Elasticsearch.&#10;&#10;        Args:&#10;            host (str): The Elasticsearch host URL.&#10;            api_key (str): The API key for authentication.&#10;            serps_index (str): The name of the SERPs index.&#10;            results_index (str): The name of the results index.&#10;        &quot;&quot;&quot;&#10;        self.serps_index = serps_index&#10;        self.results_index = results_index&#10;        self.es_client = None  # Initialize client as None&#10;&#10;        if not api_key:&#10;            print(&quot;❌ ES_API_KEY not found in .env file.&quot;)&#10;            return&#10;&#10;        try:&#10;            print(&quot;Connecting to Elasticsearch...&quot;)&#10;            # Store the client as an instance variable&#10;            self.es_client = Elasticsearch(host, api_key=api_key, verify_certs=True, request_timeout=30)&#10;            # Test connection&#10;            self.es_client.ping()&#10;            print(&quot;✅ Successfully connected to Elasticsearch!&quot;)&#10;        except Exception as e:&#10;            print(f&quot;❌ Failed to connect to Elasticsearch: {e}&quot;)&#10;            print(&#10;                &quot;Please make sure you are connected to the Webis VPN and your API key is correct.&quot;)&#10;            self.es_client = None&#10;&#10;&#10;    def get_serps(self, rag_query: str, use_provider_priority: bool = True, top_n_providers: int = 20):&#10;        &quot;&quot;&quot;&#10;        Retrieves relevant SERPs based on the user query, with optional provider prioritization.&#10;&#10;        Args:&#10;            rag_query (str): The user query string.&#10;            use_provider_priority (bool): Whether to prioritize top providers (default: True).&#10;            top_n_providers (int): Number of top providers to prioritize (default: 5).&#10;&#10;        Returns:&#10;            pd.DataFrame: DataFrame containing SERPs.&#10;        &quot;&quot;&quot;&#10;        if not self.es_client:&#10;            print(&quot;SERPs cannot be retrieved, Elasticsearch client is not connected.&quot;)&#10;            return pd.DataFrame()&#10;&#10;        # Base query structure&#10;        base_query = {&#10;            &quot;query&quot;: {&#10;                &quot;bool&quot;: {&#10;                    &quot;must&quot;: [&#10;                        {&#10;                            &quot;multi_match&quot;: {&#10;                                &quot;query&quot;: rag_query,&#10;                                &quot;fields&quot;: [&quot;warc_query&quot;]&#10;                            }&#10;                        },&#10;                        {&#10;                            &quot;nested&quot;: {&#10;                                &quot;path&quot;: &quot;warc_snippets&quot;,&#10;                                &quot;query&quot;: {&#10;                                    &quot;exists&quot;: {&#10;                                        &quot;field&quot;: &quot;warc_snippets.id&quot;  # Only results that have parsed results&#10;                                    }&#10;                                }&#10;                            }&#10;                        }&#10;                    ]&#10;                }&#10;            },&#10;            &quot;size&quot;: 50&#10;        }&#10;&#10;        # If provider priority is enabled, enhance the query&#10;        if use_provider_priority:&#10;            try:&#10;                # First, get domain counts using aggregation&#10;                domain_agg_query = {&#10;                    &quot;size&quot;: 0,  # We don't need the actual results, only aggregations&#10;                    &quot;query&quot;: {&#10;                        &quot;multi_match&quot;: {&#10;                            &quot;query&quot;: rag_query,&#10;                            &quot;fields&quot;: [&quot;warc_query&quot;, &quot;url_query&quot;]&#10;                        }&#10;                    },&#10;                    &quot;aggs&quot;: {&#10;                        &quot;domain_counts&quot;: {&#10;                            &quot;terms&quot;: {&#10;                                &quot;field&quot;: &quot;provider.domain&quot;,  # Field containing domain names&#10;                                &quot;size&quot;: top_n_providers,     # Number of top domains to return&#10;                                &quot;order&quot;: {&#10;                                    &quot;_count&quot;: &quot;desc&quot;          # Sort by frequency (descending)&#10;                                }&#10;                            }&#10;                        }&#10;                    }&#10;                }&#10;&#10;                # Execute domain aggregation query&#10;                domain_response = self.es_client.search(index=self.serps_index, body=domain_agg_query)&#10;                domain_data = domain_response[&quot;aggregations&quot;][&quot;domain_counts&quot;][&quot;buckets&quot;]&#10;&#10;                if domain_data:  # If we have domain data, enhance the query&#10;                    top_domains = [bucket[&quot;key&quot;] for bucket in domain_data]&#10;&#10;                    # Add provider boosting to the base query&#10;                    base_query[&quot;query&quot;][&quot;bool&quot;][&quot;should&quot;] = [&#10;                        {&#10;                            &quot;terms&quot;: {&#10;                                &quot;provider.domain&quot;: top_domains,&#10;                                &quot;boost&quot;: 2.0  # Boost results from top providers&#10;                            }&#10;                        }&#10;                    ]&#10;&#10;            except Exception as e:&#10;                print(f&quot;Warning: Could not retrieve domain counts, falling back to standard query: {e}&quot;)&#10;                # Continue with base query without provider priority&#10;&#10;        try:&#10;            serps = self.es_client.search(index=self.serps_index, body=base_query)&#10;&#10;            # Include provider domain in the result if available&#10;            columns = [&quot;_id&quot;, &quot;_source.warc_query&quot;, &quot;_score&quot;]&#10;            try:&#10;                # Try to include provider domain if it exists in the results&#10;                serps_df = pd.json_normalize(serps['hits']['hits'])&#10;                if &quot;_source.provider.domain&quot; in serps_df.columns:&#10;                    columns.append(&quot;_source.provider.domain&quot;)&#10;                serps_df = serps_df.loc[:, columns]&#10;            except (KeyError, IndexError):&#10;                # Fallback to basic columns if provider domain is not available&#10;                serps_df = pd.json_normalize(serps['hits']['hits']).loc[:, [&quot;_id&quot;, &quot;_source.warc_query&quot;, &quot;_score&quot;]]&#10;&#10;            return serps_df&#10;&#10;        except Exception as e:&#10;            print(f&quot;Error retrieving SERPs: {e}&quot;)&#10;            return pd.DataFrame()&#10;&#10;    def get_texts_from_index(self, serps_df: pd.DataFrame):&#10;        &quot;&quot;&quot;&#10;        Retrieves the snippet texts for the given SERPs DataFrame.&#10;&#10;        Args:&#10;            serps_df (pd.DataFrame): DataFrame containing SERP IDs.&#10;&#10;        Returns:&#10;            pd.DataFrame: DataFrame containing snippet texts.&#10;        &quot;&quot;&quot;&#10;        query = {&#10;            &quot;query&quot;: {&#10;                &quot;bool&quot;: {&#10;                    &quot;must&quot;: [&#10;                        {&#10;                            &quot;terms&quot;: {&#10;                                &quot;serp.id&quot;: serps_df[&quot;_id&quot;].values.tolist()&#10;                                # Query multiple IDs at the same time for efficiency&#10;                            },&#10;                        },&#10;                        {&#10;                            &quot;exists&quot;: {&#10;                                &quot;field&quot;: &quot;snippet.text&quot;  # Only results that have parsed texts&#10;                            }&#10;                        }&#10;                    ]&#10;                }&#10;            },&#10;            &quot;size&quot;: 10_000  # Set to maximum, to make sure we get all results&#10;        }&#10;        texts = self.es_client.search(index=self.results_index, body=query)&#10;        texts_df = pd.json_normalize(texts['hits']['hits']).loc[:,&#10;                           [&quot;_source.serp.id&quot;, &quot;_source.snippet.id&quot;, &quot;_source.snippet.text&quot;, &quot;_source.snippet.rank&quot;]]&#10;        return texts_df&#10;&#10;    def get_context(self, rag_query: str, use_provider_priority: bool = True):&#10;        &quot;&quot;&quot;&#10;        Public main method to retrieve, merge, and process data&#10;        into a final context DataFrame.&#10;&#10;        Args:&#10;            rag_query (str): The user query string.&#10;            use_provider_priority (bool): Whether to use provider prioritization (default: True).&#10;&#10;        Returns:&#10;            pd.DataFrame: DataFrame containing the final context.&#10;        &quot;&quot;&quot;&#10;        if not self.es_client:&#10;            print(&quot;Context cannot be retrieved, Elasticsearch client is not connected.&quot;)&#10;            return pd.DataFrame()&#10;&#10;        # Call get_serps with provider priority option&#10;        serps = self.get_serps(rag_query, use_provider_priority=use_provider_priority)&#10;        texts = self.get_texts_from_index(serps)&#10;&#10;        # Check if provider domain is available in serps&#10;        has_provider_domain = &quot;_source.provider.domain&quot; in serps.columns&#10;&#10;        context = (&#10;            pd.merge(&#10;                serps,&#10;                texts,&#10;                left_on=&quot;_id&quot;,&#10;                right_on=&quot;_source.serp.id&quot;,&#10;                how=&quot;inner&quot;&#10;            )&#10;            .drop(&quot;_id&quot;, axis=1)&#10;        )&#10;&#10;        # Define rename dictionary based on available columns&#10;        rename_dict = {&#10;            &quot;_source.warc_query&quot;: &quot;query&quot;,&#10;            &quot;_score&quot;: &quot;score&quot;,&#10;            &quot;_source.serp.id&quot;: &quot;serp_id&quot;,&#10;            &quot;_source.snippet.id&quot;: &quot;snippet_id&quot;,&#10;            &quot;_source.snippet.text&quot;: &quot;text&quot;,&#10;            &quot;_source.snippet.rank&quot;: &quot;rank&quot;,&#10;        }&#10;&#10;        if has_provider_domain:&#10;            rename_dict[&quot;_source.provider.domain&quot;] = &quot;provider_domain&quot;&#10;&#10;        context = context.rename(rename_dict, axis=1)&#10;&#10;        # Define final columns based on what's available&#10;        final_columns = [&quot;query&quot;, &quot;text&quot;]&#10;        if has_provider_domain and &quot;provider_domain&quot; in context.columns:&#10;            final_columns = [&quot;query&quot;, &quot;provider_domain&quot;, &quot;text&quot;]&#10;&#10;        context = (&#10;            context&#10;            .sort_values([&quot;score&quot;, &quot;rank&quot;], ascending=[False, True])&#10;            .assign(length=lambda df: df[&quot;text&quot;].apply(len))&#10;            .query(&quot;length &gt; 100&quot;)  # This can also be done in Elastic directly – try to figure out how!&#10;            .loc[:, final_columns]&#10;            .reset_index(drop=True)&#10;        )&#10;        return context" />
              <option name="updatedContent" value="import pandas as pd&#10;from dotenv import dotenv_values&#10;from elasticsearch import Elasticsearch&#10;&#10;# --- Adjust Pandas display options ---&#10;# Ensures that the entire text in the columns is displayed.&#10;pd.set_option('display.max_colwidth', None)&#10;# Ensures that all columns are displayed.&#10;pd.set_option('display.max_columns', None)&#10;# Ensures that the output optimally uses the console width.&#10;pd.set_option('display.width', None)&#10;&#10;&#10;# --- Configuration ---&#10;# Loads environment variables from the .env file.&#10;# Make sure your .env file contains the ES_API_KEY.&#10;config = dotenv_values(&quot;.env&quot;)&#10;ES_API_KEY = config.get(&quot;ES_API_KEY&quot;)&#10;&#10;# Connection parameters from your provided notebook.&#10;ES_HOST = &quot;https://elasticsearch.bw.webis.de:9200&quot;&#10;INDEX_NAME_SERPS = &quot;aql_serps&quot;&#10;INDEX_NAME_RESULTS = &quot;aql_results&quot;&#10;&#10;class SourceRetriever:&#10;    &quot;&quot;&quot;&#10;    A class for retrieving sources from Elasticsearch using advanced queries&#10;    and Pandas for data manipulation. This version uses an instance client for ES.&#10;    &quot;&quot;&quot;&#10;&#10;    def __init__(self, host: str, api_key: str, serps_index: str, results_index: str):&#10;        &quot;&quot;&quot;&#10;        Initializes the retriever and establishes the connection to Elasticsearch.&#10;&#10;        Args:&#10;            host (str): The Elasticsearch host URL.&#10;            api_key (str): The API key for authentication.&#10;            serps_index (str): The name of the SERPs index.&#10;            results_index (str): The name of the results index.&#10;        &quot;&quot;&quot;&#10;        self.serps_index = serps_index&#10;        self.results_index = results_index&#10;        self.es_client = None  # Initialize client as None&#10;&#10;        if not api_key:&#10;            print(&quot;❌ ES_API_KEY not found in .env file.&quot;)&#10;            return&#10;&#10;        try:&#10;            print(&quot;Connecting to Elasticsearch...&quot;)&#10;            # Store the client as an instance variable&#10;            self.es_client = Elasticsearch(host, api_key=api_key, verify_certs=True, request_timeout=30)&#10;            # Test connection&#10;            self.es_client.ping()&#10;            print(&quot;✅ Successfully connected to Elasticsearch!&quot;)&#10;        except Exception as e:&#10;            print(f&quot;❌ Failed to connect to Elasticsearch: {e}&quot;)&#10;            print(&#10;                &quot;Please make sure you are connected to the Webis VPN and your API key is correct.&quot;)&#10;            self.es_client = None&#10;&#10;&#10;    def get_serps(self, rag_query: str, use_provider_priority: bool = True, top_n_providers: int = 20):&#10;        &quot;&quot;&quot;&#10;        Retrieves relevant SERPs based on the user query, with optional provider prioritization.&#10;&#10;        Args:&#10;            rag_query (str): The user query string.&#10;            use_provider_priority (bool): Whether to prioritize top providers (default: True).&#10;            top_n_providers (int): Number of top providers to prioritize (default: 5).&#10;&#10;        Returns:&#10;            pd.DataFrame: DataFrame containing SERPs.&#10;        &quot;&quot;&quot;&#10;        if not self.es_client:&#10;            print(&quot;SERPs cannot be retrieved, Elasticsearch client is not connected.&quot;)&#10;            return pd.DataFrame()&#10;&#10;        # Base query structure&#10;        base_query = {&#10;            &quot;query&quot;: {&#10;                &quot;bool&quot;: {&#10;                    &quot;must&quot;: [&#10;                        {&#10;                            &quot;multi_match&quot;: {&#10;                                &quot;query&quot;: rag_query,&#10;                                &quot;fields&quot;: [&quot;warc_query&quot;]&#10;                            }&#10;                        },&#10;                        {&#10;                            &quot;nested&quot;: {&#10;                                &quot;path&quot;: &quot;warc_snippets&quot;,&#10;                                &quot;query&quot;: {&#10;                                    &quot;exists&quot;: {&#10;                                        &quot;field&quot;: &quot;warc_snippets.id&quot;  # Only results that have parsed results&#10;                                    }&#10;                                }&#10;                            }&#10;                        }&#10;                    ]&#10;                }&#10;            },&#10;            &quot;size&quot;: 50&#10;        }&#10;&#10;        # If provider priority is enabled, enhance the query&#10;        if use_provider_priority:&#10;            try:&#10;                # First, get domain counts using aggregation&#10;                domain_agg_query = {&#10;                    &quot;size&quot;: 0,  # We don't need the actual results, only aggregations&#10;                    &quot;query&quot;: {&#10;                        &quot;multi_match&quot;: {&#10;                            &quot;query&quot;: rag_query,&#10;                            &quot;fields&quot;: [&quot;warc_query&quot;, &quot;url_query&quot;]&#10;                        }&#10;                    },&#10;                    &quot;aggs&quot;: {&#10;                        &quot;domain_counts&quot;: {&#10;                            &quot;terms&quot;: {&#10;                                &quot;field&quot;: &quot;provider.domain&quot;,  # Field containing domain names&#10;                                &quot;size&quot;: top_n_providers,     # Number of top domains to return&#10;                                &quot;order&quot;: {&#10;                                    &quot;_count&quot;: &quot;desc&quot;          # Sort by frequency (descending)&#10;                                }&#10;                            }&#10;                        }&#10;                    }&#10;                }&#10;&#10;                # Execute domain aggregation query&#10;                domain_response = self.es_client.search(index=self.serps_index, body=domain_agg_query)&#10;                domain_data = domain_response[&quot;aggregations&quot;][&quot;domain_counts&quot;][&quot;buckets&quot;]&#10;&#10;                if domain_data:  # If we have domain data, enhance the query&#10;                    top_domains = [bucket[&quot;key&quot;] for bucket in domain_data]&#10;&#10;                    # Add provider boosting to the base query&#10;                    base_query[&quot;query&quot;][&quot;bool&quot;][&quot;should&quot;] = [&#10;                        {&#10;                            &quot;terms&quot;: {&#10;                                &quot;provider.domain&quot;: top_domains,&#10;                                &quot;boost&quot;: 2.0  # Boost results from top providers&#10;                            }&#10;                        }&#10;                    ]&#10;&#10;            except Exception as e:&#10;                print(f&quot;Warning: Could not retrieve domain counts, falling back to standard query: {e}&quot;)&#10;                # Continue with base query without provider priority&#10;&#10;        try:&#10;            serps = self.es_client.search(index=self.serps_index, body=base_query)&#10;&#10;            # Include provider domain in the result if available&#10;            columns = [&quot;_id&quot;, &quot;_source.warc_query&quot;, &quot;_score&quot;]&#10;            try:&#10;                # Try to include provider domain if it exists in the results&#10;                serps_df = pd.json_normalize(serps['hits']['hits'])&#10;                if &quot;_source.provider.domain&quot; in serps_df.columns:&#10;                    columns.append(&quot;_source.provider.domain&quot;)&#10;                serps_df = serps_df.loc[:, columns]&#10;            except (KeyError, IndexError):&#10;                # Fallback to basic columns if provider domain is not available&#10;                serps_df = pd.json_normalize(serps['hits']['hits']).loc[:, [&quot;_id&quot;, &quot;_source.warc_query&quot;, &quot;_score&quot;]]&#10;&#10;            return serps_df&#10;&#10;        except Exception as e:&#10;            print(f&quot;Error retrieving SERPs: {e}&quot;)&#10;            return pd.DataFrame()&#10;&#10;    def get_texts_from_index(self, serps_df: pd.DataFrame, rag_query: str = None):&#10;        &quot;&quot;&quot;&#10;        Retrieves the snippet texts for the given SERPs DataFrame.&#10;        If rag_query is provided, only returns texts that contain the query terms.&#10;&#10;        Args:&#10;            serps_df (pd.DataFrame): DataFrame containing SERP IDs.&#10;            rag_query (str, optional): The user query to filter texts by.&#10;&#10;        Returns:&#10;            pd.DataFrame: DataFrame containing snippet texts.&#10;        &quot;&quot;&quot;&#10;        must_conditions = [&#10;            {&#10;                &quot;terms&quot;: {&#10;                    &quot;serp.id&quot;: serps_df[&quot;_id&quot;].values.tolist()&#10;                    # Query multiple IDs at the same time for efficiency&#10;                },&#10;            },&#10;            {&#10;                &quot;exists&quot;: {&#10;                    &quot;field&quot;: &quot;snippet.text&quot;  # Only results that have parsed texts&#10;                }&#10;            }&#10;        ]&#10;        &#10;        # Add query match condition if rag_query is provided&#10;        if rag_query:&#10;            must_conditions.append({&#10;                &quot;match&quot;: {&#10;                    &quot;snippet.text&quot;: {&#10;                        &quot;query&quot;: rag_query,&#10;                        &quot;operator&quot;: &quot;and&quot;  # All query terms must be present&#10;                    }&#10;                }&#10;            })&#10;&#10;        query = {&#10;            &quot;query&quot;: {&#10;                &quot;bool&quot;: {&#10;                    &quot;must&quot;: must_conditions&#10;                }&#10;            },&#10;            &quot;size&quot;: 10_000  # Set to maximum, to make sure we get all results&#10;        }&#10;        texts = self.es_client.search(index=self.results_index, body=query)&#10;        texts_df = pd.json_normalize(texts['hits']['hits']).loc[:,&#10;                           [&quot;_source.serp.id&quot;, &quot;_source.snippet.id&quot;, &quot;_source.snippet.text&quot;, &quot;_source.snippet.rank&quot;]]&#10;        return texts_df&#10;&#10;    def get_context(self, rag_query: str, use_provider_priority: bool = True):&#10;        &quot;&quot;&quot;&#10;        Public main method to retrieve, merge, and process data&#10;        into a final context DataFrame.&#10;&#10;        Args:&#10;            rag_query (str): The user query string.&#10;            use_provider_priority (bool): Whether to use provider prioritization (default: True).&#10;&#10;        Returns:&#10;            pd.DataFrame: DataFrame containing the final context.&#10;        &quot;&quot;&quot;&#10;        if not self.es_client:&#10;            print(&quot;Context cannot be retrieved, Elasticsearch client is not connected.&quot;)&#10;            return pd.DataFrame()&#10;&#10;        # Call get_serps with provider priority option&#10;        serps = self.get_serps(rag_query, use_provider_priority=use_provider_priority)&#10;        texts = self.get_texts_from_index(serps, rag_query)&#10;&#10;        # Check if provider domain is available in serps&#10;        has_provider_domain = &quot;_source.provider.domain&quot; in serps.columns&#10;&#10;        context = (&#10;            pd.merge(&#10;                serps,&#10;                texts,&#10;                left_on=&quot;_id&quot;,&#10;                right_on=&quot;_source.serp.id&quot;,&#10;                how=&quot;inner&quot;&#10;            )&#10;            .drop(&quot;_id&quot;, axis=1)&#10;        )&#10;&#10;        # Define rename dictionary based on available columns&#10;        rename_dict = {&#10;            &quot;_source.warc_query&quot;: &quot;query&quot;,&#10;            &quot;_score&quot;: &quot;score&quot;,&#10;            &quot;_source.serp.id&quot;: &quot;serp_id&quot;,&#10;            &quot;_source.snippet.id&quot;: &quot;snippet_id&quot;,&#10;            &quot;_source.snippet.text&quot;: &quot;text&quot;,&#10;            &quot;_source.snippet.rank&quot;: &quot;rank&quot;,&#10;        }&#10;&#10;        if has_provider_domain:&#10;            rename_dict[&quot;_source.provider.domain&quot;] = &quot;provider_domain&quot;&#10;&#10;        context = context.rename(rename_dict, axis=1)&#10;&#10;        # Define final columns based on what's available&#10;        final_columns = [&quot;query&quot;, &quot;text&quot;]&#10;        if has_provider_domain and &quot;provider_domain&quot; in context.columns:&#10;            final_columns = [&quot;query&quot;, &quot;provider_domain&quot;, &quot;text&quot;]&#10;&#10;        context = (&#10;            context&#10;            .sort_values([&quot;score&quot;, &quot;rank&quot;], ascending=[False, True])&#10;            .assign(length=lambda df: df[&quot;text&quot;].apply(len))&#10;            .query(&quot;length &gt; 100&quot;)  # This can also be done in Elastic directly – try to figure out how!&#10;            .loc[:, final_columns]&#10;            .reset_index(drop=True)&#10;        )&#10;        return context" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>