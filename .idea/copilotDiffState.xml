<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/SourceRetriever.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/SourceRetriever.py" />
              <option name="originalContent" value="import pandas as pd&#10;from dotenv import dotenv_values&#10;from elasticsearch import Elasticsearch&#10;&#10;# --- Adjust Pandas display options ---&#10;# Ensures that the entire text in the columns is displayed.&#10;pd.set_option('display.max_colwidth', None)&#10;# Ensures that all columns are displayed.&#10;pd.set_option('display.max_columns', None)&#10;# Ensures that the output optimally uses the console width.&#10;pd.set_option('display.width', None)&#10;&#10;&#10;# --- Configuration ---&#10;# Loads environment variables from the .env file.&#10;# Make sure your .env file contains the ES_API_KEY.&#10;config = dotenv_values(&quot;.env&quot;)&#10;ES_API_KEY = config.get(&quot;ES_API_KEY&quot;)&#10;&#10;# Connection parameters from your provided notebook.&#10;ES_HOST = &quot;https://elasticsearch.bw.webis.de:9200&quot;&#10;INDEX_NAME_SERPS = &quot;aql_serps&quot;&#10;INDEX_NAME_RESULTS = &quot;aql_results&quot;&#10;&#10;class SourceRetriever:&#10;    &quot;&quot;&quot;&#10;    A class for retrieving sources from Elasticsearch using advanced queries&#10;    and Pandas for data manipulation. This version uses an instance client for ES.&#10;    &quot;&quot;&quot;&#10;&#10;    def __init__(self, host: str, api_key: str, serps_index: str, results_index: str):&#10;        &quot;&quot;&quot;&#10;        Initializes the retriever and establishes the connection to Elasticsearch.&#10;&#10;        Args:&#10;            host (str): The Elasticsearch host URL.&#10;            api_key (str): The API key for authentication.&#10;            serps_index (str): The name of the SERPs index.&#10;            results_index (str): The name of the results index.&#10;        &quot;&quot;&quot;&#10;        self.serps_index = serps_index&#10;        self.results_index = results_index&#10;        self.es_client = None  # Initialize client as None&#10;&#10;        if not api_key:&#10;            print(&quot;❌ ES_API_KEY not found in .env file.&quot;)&#10;            return&#10;&#10;        try:&#10;            print(&quot;Connecting to Elasticsearch...&quot;)&#10;            # Store the client as an instance variable&#10;            self.es_client = Elasticsearch(host, api_key=api_key, verify_certs=True, request_timeout=30)&#10;            # Test connection&#10;            self.es_client.ping()&#10;            print(&quot;✅ Successfully connected to Elasticsearch!&quot;)&#10;        except Exception as e:&#10;            print(f&quot;❌ Failed to connect to Elasticsearch: {e}&quot;)&#10;            print(&#10;                &quot;Please make sure you are connected to the Webis VPN and your API key is correct.&quot;)&#10;            self.es_client = None&#10;&#10;    def get_serps(self, rag_query: str):&#10;        &quot;&quot;&quot;&#10;        Retrieves relevant SERPs based on the user query.&#10;&#10;        Args:&#10;            rag_query (str): The user query string.&#10;&#10;        Returns:&#10;            pd.DataFrame: DataFrame containing SERPs.&#10;        &quot;&quot;&quot;&#10;        query = {&#10;            &quot;query&quot;: {&#10;                &quot;bool&quot;: {&#10;                    &quot;must&quot;: [&#10;                        {&#10;                            &quot;multi_match&quot;: {&#10;                                &quot;query&quot;: rag_query,&#10;                                &quot;fields&quot;: [&quot;warc_query&quot;]&#10;                            }&#10;                        },&#10;                        {&#10;                            &quot;nested&quot;: {&#10;                                &quot;path&quot;: &quot;warc_snippets&quot;,&#10;                                &quot;query&quot;: {&#10;                                    &quot;exists&quot;: {&#10;                                        &quot;field&quot;: &quot;warc_snippets.id&quot;  # Only results that have parsed results&#10;                                    }&#10;                                }&#10;                            }&#10;                        }&#10;                    ]&#10;                }&#10;            },&#10;            &quot;size&quot;: 10&#10;        }&#10;        serps = self.es_client.search(index=self.serps_index, body=query)&#10;        serps_df = pd.json_normalize(serps['hits']['hits']).loc[:, [&quot;_id&quot;, &quot;_source.warc_query&quot;, &quot;_score&quot;]]&#10;        return serps_df&#10;&#10;    def get_texts_from_index(self, serps_df: pd.DataFrame):&#10;        &quot;&quot;&quot;&#10;        Retrieves the snippet texts for the given SERPs DataFrame.&#10;&#10;        Args:&#10;            serps_df (pd.DataFrame): DataFrame containing SERP IDs.&#10;&#10;        Returns:&#10;            pd.DataFrame: DataFrame containing snippet texts.&#10;        &quot;&quot;&quot;&#10;        query = {&#10;            &quot;query&quot;: {&#10;                &quot;bool&quot;: {&#10;                    &quot;must&quot;: [&#10;                        {&#10;                            &quot;terms&quot;: {&#10;                                &quot;serp.id&quot;: serps_df[&quot;_id&quot;].values.tolist()&#10;                                # Query multiple IDs at the same time for efficiency&#10;                            },&#10;                        },&#10;                        {&#10;                            &quot;exists&quot;: {&#10;                                &quot;field&quot;: &quot;snippet.text&quot;  # Only results that have parsed texts&#10;                            }&#10;                        }&#10;                    ]&#10;                }&#10;            },&#10;            &quot;size&quot;: 10_000  # Set to maximum, to make sure we get all results&#10;        }&#10;        texts = self.es_client.search(index=self.results_index, body=query)&#10;        texts_df = pd.json_normalize(texts['hits']['hits']).loc[:,&#10;                           [&quot;_source.serp.id&quot;, &quot;_source.snippet.id&quot;, &quot;_source.snippet.text&quot;, &quot;_source.snippet.rank&quot;]]&#10;        return texts_df&#10;&#10;    def get_context(self, rag_query: str):&#10;        &quot;&quot;&quot;&#10;        Public main method to retrieve, merge, and process data&#10;        into a final context DataFrame.&#10;&#10;        Args:&#10;            rag_query (str): The user query string.&#10;&#10;        Returns:&#10;            pd.DataFrame: DataFrame containing the final context.&#10;        &quot;&quot;&quot;&#10;        if not self.es_client:&#10;            print(&quot;Context cannot be retrieved, Elasticsearch client is not connected.&quot;)&#10;            return pd.DataFrame()&#10;&#10;        # Calls the other methods with 'self'&#10;        serps = self.get_serps(rag_query)&#10;        texts = self.get_texts_from_index(serps)&#10;&#10;        context = (&#10;            pd.merge(&#10;                serps,&#10;                texts,&#10;                left_on=&quot;_id&quot;,&#10;                right_on=&quot;_source.serp.id&quot;,&#10;                how=&quot;inner&quot;&#10;            )&#10;            .drop(&quot;_id&quot;, axis=1)&#10;            .rename({&#10;                &quot;_source.warc_query&quot;: &quot;query&quot;,&#10;                &quot;_score&quot;: &quot;score&quot;,&#10;                &quot;_source.serp.id&quot;: &quot;serp_id&quot;,&#10;                &quot;_source.snippet.id&quot;: &quot;snippet_id&quot;,&#10;                &quot;_source.snippet.text&quot;: &quot;text&quot;,&#10;                &quot;_source.snippet.rank&quot;: &quot;rank&quot;,&#10;            }, axis=1)&#10;            .sort_values([&quot;score&quot;, &quot;rank&quot;], ascending=[False, True])&#10;            .assign(length=lambda df: df[&quot;text&quot;].apply(len)).query(&#10;                &quot;length &gt; 100&quot;)  # This can also be done in Elastic directly – try to figure out how!&#10;            .loc[:, [&quot;query&quot;, &quot;text&quot;]]&#10;            .reset_index(drop=True)&#10;        )&#10;        return context&#10;&#10;&#10;# --- Usage example ---&#10;if __name__ == '__main__':&#10;    # 1. Initialize the retriever class&#10;    retriever = SourceRetriever(&#10;        host=ES_HOST,&#10;        api_key=ES_API_KEY,&#10;        serps_index=INDEX_NAME_SERPS,&#10;        results_index=INDEX_NAME_RESULTS&#10;    )&#10;&#10;    # 2. Continue only if the connection was successful&#10;    if retriever.es_client:&#10;        user_question = &quot;pizza pineapple&quot;&#10;        print(f&quot;\n--- Retrieving context for query: '{user_question}' ---&quot;)&#10;&#10;        # 3. Call the main method to get the context&#10;        context_df = retriever.get_context(user_question)&#10;&#10;        # 4. Display the results&#10;        if not context_df.empty:&#10;            print(&quot;\n--- Retrieved context DataFrame ---&quot;)&#10;            print(context_df.head(100)) # Changed to head(100) to show more rows by default&#10;            print(f&quot;\nTotal number of retrieved snippets: {len(context_df)}&quot;)&#10;            print(&quot;-----------------------------------&quot;)&#10;        else:&#10;            print(&quot;\n--- No context was retrieved. ---&quot;)&#10;&#10;" />
              <option name="updatedContent" value="import pandas as pd&#10;from dotenv import dotenv_values&#10;from elasticsearch import Elasticsearch&#10;&#10;# --- Adjust Pandas display options ---&#10;# Ensures that the entire text in the columns is displayed.&#10;pd.set_option('display.max_colwidth', None)&#10;# Ensures that all columns are displayed.&#10;pd.set_option('display.max_columns', None)&#10;# Ensures that the output optimally uses the console width.&#10;pd.set_option('display.width', None)&#10;&#10;&#10;# --- Configuration ---&#10;# Loads environment variables from the .env file.&#10;# Make sure your .env file contains the ES_API_KEY.&#10;config = dotenv_values(&quot;.env&quot;)&#10;ES_API_KEY = config.get(&quot;ES_API_KEY&quot;)&#10;&#10;# Connection parameters from your provided notebook.&#10;ES_HOST = &quot;https://elasticsearch.bw.webis.de:9200&quot;&#10;INDEX_NAME_SERPS = &quot;aql_serps&quot;&#10;INDEX_NAME_RESULTS = &quot;aql_results&quot;&#10;&#10;class SourceRetriever:&#10;    &quot;&quot;&quot;&#10;    A class for retrieving sources from Elasticsearch using advanced queries&#10;    and Pandas for data manipulation. This version uses an instance client for ES.&#10;    &quot;&quot;&quot;&#10;&#10;    def __init__(self, host: str, api_key: str, serps_index: str, results_index: str):&#10;        &quot;&quot;&quot;&#10;        Initializes the retriever and establishes the connection to Elasticsearch.&#10;&#10;        Args:&#10;            host (str): The Elasticsearch host URL.&#10;            api_key (str): The API key for authentication.&#10;            serps_index (str): The name of the SERPs index.&#10;            results_index (str): The name of the results index.&#10;        &quot;&quot;&quot;&#10;        self.serps_index = serps_index&#10;        self.results_index = results_index&#10;        self.es_client = None  # Initialize client as None&#10;&#10;        if not api_key:&#10;            print(&quot;❌ ES_API_KEY not found in .env file.&quot;)&#10;            return&#10;&#10;        try:&#10;            print(&quot;Connecting to Elasticsearch...&quot;)&#10;            # Store the client as an instance variable&#10;            self.es_client = Elasticsearch(host, api_key=api_key, verify_certs=True, request_timeout=30)&#10;            # Test connection&#10;            self.es_client.ping()&#10;            print(&quot;✅ Successfully connected to Elasticsearch!&quot;)&#10;        except Exception as e:&#10;            print(f&quot;❌ Failed to connect to Elasticsearch: {e}&quot;)&#10;            print(&#10;                &quot;Please make sure you are connected to the Webis VPN and your API key is correct.&quot;)&#10;            self.es_client = None&#10;&#10;    def get_domain_counts(self, rag_query: str, size: int = 20):&#10;        &quot;&quot;&quot;&#10;        Retrieves domain counts aggregation for a given query to identify top providers.&#10;&#10;        Args:&#10;            rag_query (str): The user query string.&#10;            size (int): Number of top domains to return (default: 20).&#10;&#10;        Returns:&#10;            pd.DataFrame: DataFrame containing domain counts.&#10;        &quot;&quot;&quot;&#10;        if not self.es_client:&#10;            print(&quot;Domain counts cannot be retrieved, Elasticsearch client is not connected.&quot;)&#10;            return pd.DataFrame()&#10;&#10;        query = {&#10;            &quot;size&quot;: 0,  # We don't need the actual results, only aggregations&#10;            &quot;query&quot;: {&#10;                &quot;multi_match&quot;: {&#10;                    &quot;query&quot;: rag_query,&#10;                    &quot;fields&quot;: [&quot;warc_query&quot;, &quot;url_query&quot;]&#10;                }&#10;            },&#10;            &quot;aggs&quot;: {&#10;                &quot;domain_counts&quot;: {&#10;                    &quot;terms&quot;: {&#10;                        &quot;field&quot;: &quot;provider.domain&quot;,  # Field containing domain names&#10;                        &quot;size&quot;: size,                # Number of top domains to return&#10;                        &quot;order&quot;: {&#10;                            &quot;_count&quot;: &quot;desc&quot;         # Sort by frequency (descending)&#10;                        }&#10;                    }&#10;                }&#10;            }&#10;        }&#10;&#10;        try:&#10;            response = self.es_client.search(index=self.serps_index, body=query)&#10;            domain_data = response[&quot;aggregations&quot;][&quot;domain_counts&quot;][&quot;buckets&quot;]&#10;            &#10;            domain_df = pd.DataFrame(domain_data).rename({&#10;                &quot;key&quot;: &quot;domain&quot;,&#10;                &quot;doc_count&quot;: &quot;count&quot;&#10;            }, axis=1)&#10;            &#10;            return domain_df&#10;        except Exception as e:&#10;            print(f&quot;Error retrieving domain counts: {e}&quot;)&#10;            return pd.DataFrame()&#10;&#10;    def get_serps_with_top_providers(self, rag_query: str, top_n_providers: int = 5):&#10;        &quot;&quot;&quot;&#10;        Retrieves relevant SERPs based on the user query, prioritizing top providers.&#10;&#10;        Args:&#10;            rag_query (str): The user query string.&#10;            top_n_providers (int): Number of top providers to prioritize (default: 5).&#10;&#10;        Returns:&#10;            pd.DataFrame: DataFrame containing SERPs with provider priority.&#10;        &quot;&quot;&quot;&#10;        if not self.es_client:&#10;            print(&quot;SERPs cannot be retrieved, Elasticsearch client is not connected.&quot;)&#10;            return pd.DataFrame()&#10;&#10;        # First, get top domains for this query&#10;        domain_counts = self.get_domain_counts(rag_query, size=top_n_providers)&#10;        &#10;        if domain_counts.empty:&#10;            # Fallback to original method if no domain data&#10;            return self.get_serps(rag_query)&#10;&#10;        top_domains = domain_counts[&quot;domain&quot;].tolist()&#10;        &#10;        # Enhanced query that boosts results from top providers&#10;        query = {&#10;            &quot;query&quot;: {&#10;                &quot;bool&quot;: {&#10;                    &quot;must&quot;: [&#10;                        {&#10;                            &quot;multi_match&quot;: {&#10;                                &quot;query&quot;: rag_query,&#10;                                &quot;fields&quot;: [&quot;warc_query&quot;]&#10;                            }&#10;                        },&#10;                        {&#10;                            &quot;nested&quot;: {&#10;                                &quot;path&quot;: &quot;warc_snippets&quot;,&#10;                                &quot;query&quot;: {&#10;                                    &quot;exists&quot;: {&#10;                                        &quot;field&quot;: &quot;warc_snippets.id&quot;&#10;                                    }&#10;                                }&#10;                            }&#10;                        }&#10;                    ],&#10;                    &quot;should&quot;: [&#10;                        {&#10;                            &quot;terms&quot;: {&#10;                                &quot;provider.domain&quot;: top_domains,&#10;                                &quot;boost&quot;: 2.0  # Boost results from top providers&#10;                            }&#10;                        }&#10;                    ]&#10;                }&#10;            },&#10;            &quot;size&quot;: 10&#10;        }&#10;        &#10;        try:&#10;            serps = self.es_client.search(index=self.serps_index, body=query)&#10;            serps_df = pd.json_normalize(serps['hits']['hits']).loc[:, &#10;                       [&quot;_id&quot;, &quot;_source.warc_query&quot;, &quot;_source.provider.domain&quot;, &quot;_score&quot;]]&#10;            return serps_df&#10;        except Exception as e:&#10;            print(f&quot;Error retrieving SERPs with top providers: {e}&quot;)&#10;            return self.get_serps(rag_query)  # Fallback to original method&#10;&#10;    def get_serps(self, rag_query: str, use_provider_priority: bool = True, top_n_providers: int = 5):&#10;        &quot;&quot;&quot;&#10;        Retrieves relevant SERPs based on the user query, with optional provider prioritization.&#10;&#10;        Args:&#10;            rag_query (str): The user query string.&#10;            use_provider_priority (bool): Whether to prioritize top providers (default: True).&#10;            top_n_providers (int): Number of top providers to prioritize (default: 5).&#10;&#10;        Returns:&#10;            pd.DataFrame: DataFrame containing SERPs.&#10;        &quot;&quot;&quot;&#10;        if not self.es_client:&#10;            print(&quot;SERPs cannot be retrieved, Elasticsearch client is not connected.&quot;)&#10;            return pd.DataFrame()&#10;&#10;        # Base query structure&#10;        base_query = {&#10;            &quot;query&quot;: {&#10;                &quot;bool&quot;: {&#10;                    &quot;must&quot;: [&#10;                        {&#10;                            &quot;multi_match&quot;: {&#10;                                &quot;query&quot;: rag_query,&#10;                                &quot;fields&quot;: [&quot;warc_query&quot;]&#10;                            }&#10;                        },&#10;                        {&#10;                            &quot;nested&quot;: {&#10;                                &quot;path&quot;: &quot;warc_snippets&quot;,&#10;                                &quot;query&quot;: {&#10;                                    &quot;exists&quot;: {&#10;                                        &quot;field&quot;: &quot;warc_snippets.id&quot;  # Only results that have parsed results&#10;                                    }&#10;                                }&#10;                            }&#10;                        }&#10;                    ]&#10;                }&#10;            },&#10;            &quot;size&quot;: 10&#10;        }&#10;&#10;        # If provider priority is enabled, enhance the query&#10;        if use_provider_priority:&#10;            try:&#10;                # First, get domain counts using aggregation&#10;                domain_agg_query = {&#10;                    &quot;size&quot;: 0,  # We don't need the actual results, only aggregations&#10;                    &quot;query&quot;: {&#10;                        &quot;multi_match&quot;: {&#10;                            &quot;query&quot;: rag_query,&#10;                            &quot;fields&quot;: [&quot;warc_query&quot;, &quot;url_query&quot;]&#10;                        }&#10;                    },&#10;                    &quot;aggs&quot;: {&#10;                        &quot;domain_counts&quot;: {&#10;                            &quot;terms&quot;: {&#10;                                &quot;field&quot;: &quot;provider.domain&quot;,  # Field containing domain names&#10;                                &quot;size&quot;: top_n_providers,     # Number of top domains to return&#10;                                &quot;order&quot;: {&#10;                                    &quot;_count&quot;: &quot;desc&quot;          # Sort by frequency (descending)&#10;                                }&#10;                            }&#10;                        }&#10;                    }&#10;                }&#10;&#10;                # Execute domain aggregation query&#10;                domain_response = self.es_client.search(index=self.serps_index, body=domain_agg_query)&#10;                domain_data = domain_response[&quot;aggregations&quot;][&quot;domain_counts&quot;][&quot;buckets&quot;]&#10;                &#10;                if domain_data:  # If we have domain data, enhance the query&#10;                    top_domains = [bucket[&quot;key&quot;] for bucket in domain_data]&#10;                    &#10;                    # Add provider boosting to the base query&#10;                    base_query[&quot;query&quot;][&quot;bool&quot;][&quot;should&quot;] = [&#10;                        {&#10;                            &quot;terms&quot;: {&#10;                                &quot;provider.domain&quot;: top_domains,&#10;                                &quot;boost&quot;: 2.0  # Boost results from top providers&#10;                            }&#10;                        }&#10;                    ]&#10;&#10;            except Exception as e:&#10;                print(f&quot;Warning: Could not retrieve domain counts, falling back to standard query: {e}&quot;)&#10;                # Continue with base query without provider priority&#10;&#10;        try:&#10;            serps = self.es_client.search(index=self.serps_index, body=base_query)&#10;            &#10;            # Include provider domain in the result if available&#10;            columns = [&quot;_id&quot;, &quot;_source.warc_query&quot;, &quot;_score&quot;]&#10;            try:&#10;                # Try to include provider domain if it exists in the results&#10;                serps_df = pd.json_normalize(serps['hits']['hits'])&#10;                if &quot;_source.provider.domain&quot; in serps_df.columns:&#10;                    columns.append(&quot;_source.provider.domain&quot;)&#10;                serps_df = serps_df.loc[:, columns]&#10;            except (KeyError, IndexError):&#10;                # Fallback to basic columns if provider domain is not available&#10;                serps_df = pd.json_normalize(serps['hits']['hits']).loc[:, [&quot;_id&quot;, &quot;_source.warc_query&quot;, &quot;_score&quot;]]&#10;            &#10;            return serps_df&#10;            &#10;        except Exception as e:&#10;            print(f&quot;Error retrieving SERPs: {e}&quot;)&#10;            return pd.DataFrame()&#10;&#10;    def get_texts_from_index(self, serps_df: pd.DataFrame):&#10;        &quot;&quot;&quot;&#10;        Retrieves the snippet texts for the given SERPs DataFrame.&#10;&#10;        Args:&#10;            serps_df (pd.DataFrame): DataFrame containing SERP IDs.&#10;&#10;        Returns:&#10;            pd.DataFrame: DataFrame containing snippet texts.&#10;        &quot;&quot;&quot;&#10;        query = {&#10;            &quot;query&quot;: {&#10;                &quot;bool&quot;: {&#10;                    &quot;must&quot;: [&#10;                        {&#10;                            &quot;terms&quot;: {&#10;                                &quot;serp.id&quot;: serps_df[&quot;_id&quot;].values.tolist()&#10;                                # Query multiple IDs at the same time for efficiency&#10;                            },&#10;                        },&#10;                        {&#10;                            &quot;exists&quot;: {&#10;                                &quot;field&quot;: &quot;snippet.text&quot;  # Only results that have parsed texts&#10;                            }&#10;                        }&#10;                    ]&#10;                }&#10;            },&#10;            &quot;size&quot;: 10_000  # Set to maximum, to make sure we get all results&#10;        }&#10;        texts = self.es_client.search(index=self.results_index, body=query)&#10;        texts_df = pd.json_normalize(texts['hits']['hits']).loc[:,&#10;                           [&quot;_source.serp.id&quot;, &quot;_source.snippet.id&quot;, &quot;_source.snippet.text&quot;, &quot;_source.snippet.rank&quot;]]&#10;        return texts_df&#10;&#10;    def get_context_with_provider_priority(self, rag_query: str, top_n_providers: int = 5):&#10;        &quot;&quot;&quot;&#10;        Enhanced context retrieval method that prioritizes top providers.&#10;&#10;        Args:&#10;            rag_query (str): The user query string.&#10;            top_n_providers (int): Number of top providers to prioritize.&#10;&#10;        Returns:&#10;            pd.DataFrame: DataFrame containing the final context with provider information.&#10;        &quot;&quot;&quot;&#10;        if not self.es_client:&#10;            print(&quot;Context cannot be retrieved, Elasticsearch client is not connected.&quot;)&#10;            return pd.DataFrame()&#10;&#10;        # Get SERPs with provider priority&#10;        serps = self.get_serps_with_top_providers(rag_query, top_n_providers)&#10;        texts = self.get_texts_from_index(serps)&#10;&#10;        context = (&#10;            pd.merge(&#10;                serps,&#10;                texts,&#10;                left_on=&quot;_id&quot;,&#10;                right_on=&quot;_source.serp.id&quot;,&#10;                how=&quot;inner&quot;&#10;            )&#10;            .drop(&quot;_id&quot;, axis=1)&#10;            .rename({&#10;                &quot;_source.warc_query&quot;: &quot;query&quot;,&#10;                &quot;_score&quot;: &quot;score&quot;,&#10;                &quot;_source.provider.domain&quot;: &quot;provider_domain&quot;,&#10;                &quot;_source.serp.id&quot;: &quot;serp_id&quot;,&#10;                &quot;_source.snippet.id&quot;: &quot;snippet_id&quot;,&#10;                &quot;_source.snippet.text&quot;: &quot;text&quot;,&#10;                &quot;_source.snippet.rank&quot;: &quot;rank&quot;,&#10;            }, axis=1)&#10;            .sort_values([&quot;score&quot;, &quot;rank&quot;], ascending=[False, True])&#10;            .assign(length=lambda df: df[&quot;text&quot;].apply(len)).query(&quot;length &gt; 100&quot;)&#10;            .loc[:, [&quot;query&quot;, &quot;provider_domain&quot;, &quot;text&quot;]]&#10;            .reset_index(drop=True)&#10;        )&#10;        return context&#10;&#10;    def get_context(self, rag_query: str, use_provider_priority: bool = True):&#10;        &quot;&quot;&quot;&#10;        Public main method to retrieve, merge, and process data&#10;        into a final context DataFrame.&#10;&#10;        Args:&#10;            rag_query (str): The user query string.&#10;            use_provider_priority (bool): Whether to use provider prioritization (default: True).&#10;&#10;        Returns:&#10;            pd.DataFrame: DataFrame containing the final context.&#10;        &quot;&quot;&quot;&#10;        if not self.es_client:&#10;            print(&quot;Context cannot be retrieved, Elasticsearch client is not connected.&quot;)&#10;            return pd.DataFrame()&#10;&#10;        # Call get_serps with provider priority option&#10;        serps = self.get_serps(rag_query, use_provider_priority=use_provider_priority)&#10;        texts = self.get_texts_from_index(serps)&#10;&#10;        # Check if provider domain is available in serps&#10;        has_provider_domain = &quot;_source.provider.domain&quot; in serps.columns&#10;&#10;        context = (&#10;            pd.merge(&#10;                serps,&#10;                texts,&#10;                left_on=&quot;_id&quot;,&#10;                right_on=&quot;_source.serp.id&quot;,&#10;                how=&quot;inner&quot;&#10;            )&#10;            .drop(&quot;_id&quot;, axis=1)&#10;        )&#10;&#10;        # Define rename dictionary based on available columns&#10;        rename_dict = {&#10;            &quot;_source.warc_query&quot;: &quot;query&quot;,&#10;            &quot;_score&quot;: &quot;score&quot;,&#10;            &quot;_source.serp.id&quot;: &quot;serp_id&quot;,&#10;            &quot;_source.snippet.id&quot;: &quot;snippet_id&quot;,&#10;            &quot;_source.snippet.text&quot;: &quot;text&quot;,&#10;            &quot;_source.snippet.rank&quot;: &quot;rank&quot;,&#10;        }&#10;        &#10;        if has_provider_domain:&#10;            rename_dict[&quot;_source.provider.domain&quot;] = &quot;provider_domain&quot;&#10;&#10;        context = context.rename(rename_dict, axis=1)&#10;&#10;        # Define final columns based on what's available&#10;        final_columns = [&quot;query&quot;, &quot;text&quot;]&#10;        if has_provider_domain and &quot;provider_domain&quot; in context.columns:&#10;            final_columns = [&quot;query&quot;, &quot;provider_domain&quot;, &quot;text&quot;]&#10;&#10;        context = (&#10;            context&#10;            .sort_values([&quot;score&quot;, &quot;rank&quot;], ascending=[False, True])&#10;            .assign(length=lambda df: df[&quot;text&quot;].apply(len))&#10;            .query(&quot;length &gt; 100&quot;)  # This can also be done in Elastic directly – try to figure out how!&#10;            .loc[:, final_columns]&#10;            .reset_index(drop=True)&#10;        )&#10;        return context&#10;&#10;&#10;# --- Usage example ---&#10;if __name__ == '__main__':&#10;    # 1. Initialize the retriever class&#10;    retriever = SourceRetriever(&#10;        host=ES_HOST,&#10;        api_key=ES_API_KEY,&#10;        serps_index=INDEX_NAME_SERPS,&#10;        results_index=INDEX_NAME_RESULTS&#10;    )&#10;&#10;    # 2. Continue only if the connection was successful&#10;    if retriever.es_client:&#10;        user_question = &quot;pizza pineapple&quot;&#10;        print(f&quot;\n--- Retrieving context for query: '{user_question}' ---&quot;)&#10;&#10;        # 3a. First, show domain counts for the query&#10;        print(&quot;\n--- Top Provider Domains for this query ---&quot;)&#10;        domain_counts = retriever.get_domain_counts(user_question)&#10;        if not domain_counts.empty:&#10;            print(domain_counts.head(10))&#10;        else:&#10;            print(&quot;No domain data found.&quot;)&#10;&#10;        # 3b. Call the enhanced method with provider priority&#10;        print(f&quot;\n--- Using provider-prioritized context retrieval ---&quot;)&#10;        context_df_enhanced = retriever.get_context_with_provider_priority(user_question, top_n_providers=5)&#10;&#10;        # 3c. Call the original method for comparison&#10;        print(f&quot;\n--- Using original context retrieval ---&quot;)&#10;        context_df_original = retriever.get_context(user_question)&#10;&#10;        # 4. Display and compare the results&#10;        if not context_df_enhanced.empty:&#10;            print(&quot;\n--- Enhanced context DataFrame (with provider priority) ---&quot;)&#10;            print(context_df_enhanced.head(10))&#10;            print(f&quot;\nTotal number of retrieved snippets (enhanced): {len(context_df_enhanced)}&quot;)&#10;            &#10;            if 'provider_domain' in context_df_enhanced.columns:&#10;                print(&quot;\n--- Provider domain distribution in enhanced results ---&quot;)&#10;                print(context_df_enhanced['provider_domain'].value_counts().head(10))&#10;            print(&quot;-----------------------------------&quot;)&#10;        else:&#10;            print(&quot;\n--- No enhanced context was retrieved. ---&quot;)&#10;&#10;        if not context_df_original.empty:&#10;            print(&quot;\n--- Original context DataFrame ---&quot;)&#10;            print(context_df_original.head(10))&#10;            print(f&quot;\nTotal number of retrieved snippets (original): {len(context_df_original)}&quot;)&#10;            print(&quot;-----------------------------------&quot;)&#10;        else:&#10;            print(&quot;\n--- No original context was retrieved. ---&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/app.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app.py" />
              <option name="originalContent" value="import streamlit as st&#10;import pandas as pd&#10;from SourceRetriever import SourceRetriever&#10;from LLM import LLM&#10;from dotenv import dotenv_values&#10;import random&#10;import io&#10;&#10;# --- Page Configuration ---&#10;st.set_page_config(&#10;    page_title=&quot;RAG Pipeline Analysis Tool&quot;,&#10;    page_icon=&quot;&quot;,&#10;    layout=&quot;wide&quot;&#10;)&#10;&#10;# --- Initialize Session State for Navigation ---&#10;if 'page' not in st.session_state:&#10;    st.session_state.page = 'analysis'&#10;&#10;# --- Navigation ---&#10;col1, col2 = st.columns([4, 1])&#10;with col2:&#10;    if st.session_state.page == 'analysis':&#10;        if st.button(&quot; Go to Ranking Tool&quot;, use_container_width=True):&#10;            st.session_state.page = 'ranking'&#10;            st.rerun()&#10;    else:&#10;        if st.button(&quot; Back to Analysis Tool&quot;, use_container_width=True):&#10;            st.session_state.page = 'analysis'&#10;            st.rerun()&#10;&#10;# --- Pipeline Functions ---&#10;def run_pipeline_1(query, retriever, llm_generator):&#10;    &quot;&quot;&quot;Pipeline 1: Original Query (Direct Context → Filter → Answer)&quot;&quot;&quot;&#10;    try:&#10;        context_df = retriever.get_context(query)&#10;        original_context = context_df.copy() if not context_df.empty else pd.DataFrame()&#10;&#10;        if not context_df.empty:&#10;            # Apply context filtering for Pipeline 1&#10;            filtered_context_df = llm_generator.filter_context(context_df, query)&#10;&#10;            if not filtered_context_df.empty:&#10;                answer = llm_generator.answer_question_from_context(filtered_context_df, query)&#10;                return {&#10;                    'answer': answer or &quot;Could not generate an answer.&quot;,&#10;                    'original_context': original_context,&#10;                    'filtered_context': filtered_context_df&#10;                }&#10;            else:&#10;                return {&#10;                    'answer': &quot;No relevant context found for this query.&quot;,&#10;                    'original_context': original_context,&#10;                    'filtered_context': pd.DataFrame()&#10;                }&#10;        return {&#10;            'answer': &quot;No context retrieved.&quot;,&#10;            'original_context': pd.DataFrame(),&#10;            'filtered_context': pd.DataFrame()&#10;        }&#10;    except Exception as e:&#10;        return {&#10;            'answer': f&quot;Error in Pipeline 1: {str(e)}&quot;,&#10;            'original_context': pd.DataFrame(),&#10;            'filtered_context': pd.DataFrame()&#10;        }&#10;&#10;def run_pipeline_2(query, retriever, llm_generator):&#10;    &quot;&quot;&quot;Pipeline 2: Original Query (Summary → Answer)&quot;&quot;&quot;&#10;    try:&#10;        context_df = retriever.get_context(query)&#10;&#10;        if not context_df.empty:&#10;            summarized_context = llm_generator.summarize_context(context_df, query)&#10;            if summarized_context:&#10;                answer = llm_generator.answer_question_from_summary(summarized_context, query)&#10;                return {&#10;                    'answer': answer or &quot;Could not generate an answer.&quot;,&#10;                    'context': context_df,&#10;                    'summary': summarized_context&#10;                }&#10;        return {&#10;            'answer': &quot;No context retrieved.&quot;,&#10;            'context': pd.DataFrame(),&#10;            'summary': &quot;&quot;&#10;        }&#10;    except Exception as e:&#10;        return {&#10;            'answer': f&quot;Error in Pipeline 2: {str(e)}&quot;,&#10;            'context': pd.DataFrame(),&#10;            'summary': &quot;&quot;&#10;        }&#10;&#10;def run_pipeline_3(query, retriever, llm_generator):&#10;    &quot;&quot;&quot;Pipeline 3: Rewritten Query (Rewrite → Summary → Answer)&quot;&quot;&quot;&#10;    try:&#10;        rewritten_query = llm_generator.rewrite_query(query)&#10;        context_df = retriever.get_context(rewritten_query)&#10;&#10;        if not context_df.empty:&#10;            summarized_context = llm_generator.summarize_context(context_df, query)&#10;            if summarized_context:&#10;                answer = llm_generator.answer_question_from_summary(summarized_context, query)&#10;                return {&#10;                    'answer': answer or &quot;Could not generate an answer.&quot;,&#10;                    'rewritten_query': rewritten_query,&#10;                    'context': context_df,&#10;                    'summary': summarized_context&#10;                }&#10;        return {&#10;            'answer': &quot;No context retrieved for rewritten query.&quot;,&#10;            'rewritten_query': rewritten_query,&#10;            'context': pd.DataFrame(),&#10;            'summary': &quot;&quot;&#10;        }&#10;    except Exception as e:&#10;        return {&#10;            'answer': f&quot;Error in Pipeline 3: {str(e)}&quot;,&#10;            'rewritten_query': query,&#10;            'context': pd.DataFrame(),&#10;            'summary': &quot;&quot;&#10;        }&#10;&#10;def run_pipeline_4(query, retriever, llm_generator):&#10;    &quot;&quot;&quot;Pipeline 4: Query Pool (Query Pool → Filtered Context → Direct Answer)&quot;&quot;&quot;&#10;    try:&#10;        query_pool = llm_generator.generate_query_pool(query, 4)&#10;        all_contexts = []&#10;        for q in query_pool:&#10;            pooled_df = retriever.get_context(q)&#10;            if not pooled_df.empty:&#10;                all_contexts.append(pooled_df)&#10;&#10;        if all_contexts:&#10;            full_context_df = pd.concat(all_contexts, ignore_index=True).drop_duplicates(&#10;                subset=['text']).reset_index(drop=True)&#10;            truncated_pool_df = full_context_df.head(100)&#10;            original_context = truncated_pool_df.copy()&#10;&#10;            # Apply context filtering for Pipeline 4&#10;            filtered_context_df = llm_generator.filter_context(truncated_pool_df, query)&#10;&#10;            if not filtered_context_df.empty:&#10;                answer = llm_generator.answer_question_from_context(filtered_context_df, query)&#10;                return {&#10;                    'answer': answer or &quot;Could not generate an answer.&quot;,&#10;                    'query_pool': query_pool,&#10;                    'original_context': original_context,&#10;                    'filtered_context': filtered_context_df&#10;                }&#10;            else:&#10;                return {&#10;                    'answer': &quot;No relevant context found for this query.&quot;,&#10;                    'query_pool': query_pool,&#10;                    'original_context': original_context,&#10;                    'filtered_context': pd.DataFrame()&#10;                }&#10;        return {&#10;            'answer': &quot;No context retrieved from query pool.&quot;,&#10;            'query_pool': query_pool,&#10;            'original_context': pd.DataFrame(),&#10;            'filtered_context': pd.DataFrame()&#10;        }&#10;    except Exception as e:&#10;        return {&#10;            'answer': f&quot;Error in Pipeline 4: {str(e)}&quot;,&#10;            'query_pool': [],&#10;            'original_context': pd.DataFrame(),&#10;            'filtered_context': pd.DataFrame()&#10;        }&#10;&#10;# --- Load API Keys ---&#10;@st.cache_data&#10;def load_config():&#10;    try:&#10;        config = dotenv_values(&quot;.env&quot;)&#10;        es_api_key = config.get(&quot;ES_API_KEY&quot;)&#10;        llm_api_key = config.get(&quot;API_KEY&quot;)&#10;        if not es_api_key or not llm_api_key:&#10;            st.error(&#10;                &quot;API keys (ES_API_KEY, API_KEY) not found in your .env file. Please make sure it's configured correctly.&quot;)&#10;            return None, None&#10;        return es_api_key, llm_api_key&#10;    except Exception as e:&#10;        st.error(f&quot;Could not load the .env file. Please make sure it exists in the root directory. Error: {e}&quot;)&#10;        return None, None&#10;&#10;ES_API_KEY, LLM_API_KEY = load_config()&#10;&#10;if not ES_API_KEY or not LLM_API_KEY:&#10;    st.stop()&#10;&#10;# --- Caching the Clients ---&#10;@st.cache_resource&#10;def get_retriever():&#10;    retriever = SourceRetriever(&#10;        host=&quot;https://elasticsearch.bw.webis.de:9200&quot;,&#10;        api_key=ES_API_KEY,&#10;        serps_index=&quot;aql_serps&quot;,&#10;        results_index=&quot;aql_results&quot;&#10;    )&#10;    if not retriever.es_client:&#10;        st.error(&quot;Failed to connect to Elasticsearch. Please check your VPN and API key.&quot;)&#10;        return None&#10;    return retriever&#10;&#10;@st.cache_resource&#10;def get_llm_generator():&#10;    llm = LLM(&#10;        api_key=LLM_API_KEY,&#10;        base_url=&quot;https://api.helmholtz-blablador.fz-juelich.de/v1/&quot;,&#10;        model=&quot;alias-fast-experimental&quot;&#10;    )&#10;    if not llm.client:&#10;        st.error(&quot;Failed to initialize the LLM client. Please check your API key.&quot;)&#10;        return None&#10;    return llm&#10;&#10;# --- Main App Logic based on page state ---&#10;if st.session_state.page == 'analysis':&#10;    # --- Analysis Mode ---&#10;    st.title(&quot; RAG Pipeline Analysis Tool&quot;)&#10;    st.markdown(&#10;        &quot;&quot;&quot;&#10;    This application allows you to test and compare different Retrieval-Augmented Generation (RAG) strategies. &#10;    Enter a question below and click 'Run Analysis' to see how each pipeline performs.&#10;    &quot;&quot;&quot;&#10;    )&#10;&#10;    retriever = get_retriever()&#10;    llm_generator = get_llm_generator()&#10;&#10;    if not retriever or not llm_generator:&#10;        st.warning(&quot;One or more services could not be initialized. The app cannot proceed.&quot;)&#10;        st.stop()&#10;&#10;    user_question = st.text_input(&#10;        &quot;Enter your question here:&quot;,&#10;        &quot;Seven Wonders of the World&quot;&#10;    )&#10;&#10;    if st.button(&quot;Run Analysis&quot;, type=&quot;primary&quot;):&#10;        if not user_question:&#10;            st.warning(&quot;Please enter a question.&quot;)&#10;        else:&#10;            st.success(f&quot;Processing query: **{user_question}**&quot;)&#10;&#10;            # --- Pipeline 1: Original Query (Direct Context → Filter → Answer) ---&#10;            st.header(&quot;Pipeline 1: Original Query (Direct Context → Filter → Answer)&quot;)&#10;            with st.spinner(&quot;Running Pipeline 1...&quot;):&#10;                pipeline1_result = run_pipeline_1(user_question, retriever, llm_generator)&#10;&#10;            if not pipeline1_result['original_context'].empty:&#10;                st.info(f&quot;Retrieved **{len(pipeline1_result['original_context'])}** snippets, filtered to **{len(pipeline1_result['filtered_context'])}** relevant snippets.&quot;)&#10;&#10;                col1, col2 = st.columns(2)&#10;                with col1:&#10;                    with st.expander(&quot;Show Original Context&quot;):&#10;                        st.dataframe(pipeline1_result['original_context'])&#10;                with col2:&#10;                    with st.expander(&quot;Show Filtered Context&quot;):&#10;                        if not pipeline1_result['filtered_context'].empty:&#10;                            st.dataframe(pipeline1_result['filtered_context'])&#10;                        else:&#10;                            st.info(&quot;No relevant context found after filtering.&quot;)&#10;&#10;                st.subheader(&quot;Final Answer&quot;)&#10;                st.success(pipeline1_result['answer'])&#10;            else:&#10;                st.warning(&quot;No context was retrieved for Pipeline 1.&quot;)&#10;&#10;            # --- Pipeline 2: Original Query (Summary → Answer) ---&#10;            st.header(&quot;Pipeline 2: Original Query (Summary → Answer)&quot;)&#10;            with st.spinner(&quot;Running Pipeline 2...&quot;):&#10;                pipeline2_result = run_pipeline_2(user_question, retriever, llm_generator)&#10;&#10;            if not pipeline2_result['context'].empty:&#10;                st.info(f&quot;Retrieved **{len(pipeline2_result['context'])}** snippets for Pipeline 2.&quot;)&#10;                with st.expander(&quot;Show Retrieved Context for Pipeline 2&quot;):&#10;                    st.dataframe(pipeline2_result['context'])&#10;&#10;                with st.expander(&quot;Show Pipeline 2 Result&quot;):&#10;                    st.subheader(&quot;Intermediate Summary&quot;)&#10;                    st.write(pipeline2_result['summary'] or &quot;Could not generate summary.&quot;)&#10;                    st.subheader(&quot;Final Answer&quot;)&#10;                    st.success(pipeline2_result['answer'])&#10;            else:&#10;                st.warning(&quot;No context was retrieved for Pipeline 2.&quot;)&#10;&#10;            # --- Pipeline 3: Rewritten Query (Rewrite → Summary → Answer) ---&#10;            st.header(&quot;Pipeline 3: Rewritten Query (Rewrite → Summary → Answer)&quot;)&#10;            with st.spinner(&quot;Running Pipeline 3...&quot;):&#10;                pipeline3_result = run_pipeline_3(user_question, retriever, llm_generator)&#10;&#10;            st.subheader(&quot;LLM-Rewritten Query&quot;)&#10;            st.info(f&quot;**{pipeline3_result['rewritten_query']}**&quot;)&#10;&#10;            if not pipeline3_result['context'].empty:&#10;                st.info(f&quot;Retrieved **{len(pipeline3_result['context'])}** snippets for Pipeline 3.&quot;)&#10;                with st.expander(&quot;Show Retrieved Context for Pipeline 3&quot;):&#10;                    st.dataframe(pipeline3_result['context'])&#10;&#10;                with st.expander(&quot;Show Pipeline 3 Result&quot;):&#10;                    st.subheader(&quot;Intermediate Summary&quot;)&#10;                    st.write(pipeline3_result['summary'] or &quot;Could not generate summary.&quot;)&#10;                    st.subheader(&quot;Final Answer&quot;)&#10;                    st.success(pipeline3_result['answer'])&#10;            else:&#10;                st.warning(&quot;No context was retrieved for Pipeline 3.&quot;)&#10;&#10;            # --- Pipeline 4: Query Pool (Query Pool → Filtered Context → Direct Answer) ---&#10;            st.header(&quot;Pipeline 4: Query Pool (Query Pool → Filtered Context → Direct Answer)&quot;)&#10;            with st.spinner(&quot;Running Pipeline 4...&quot;):&#10;                pipeline4_result = run_pipeline_4(user_question, retriever, llm_generator)&#10;&#10;            if pipeline4_result['query_pool']:&#10;                st.subheader(&quot;Generated Query Pool&quot;)&#10;                for i, query in enumerate(pipeline4_result['query_pool'], 1):&#10;                    st.write(f&quot;{i}. {query}&quot;)&#10;&#10;            if not pipeline4_result['original_context'].empty:&#10;                st.info(f&quot;Retrieved **{len(pipeline4_result['original_context'])}** total unique snippets, filtered to **{len(pipeline4_result['filtered_context'])}** relevant snippets.&quot;)&#10;&#10;                col1, col2 = st.columns(2)&#10;                with col1:&#10;                    with st.expander(&quot;Show Original Pooled Context&quot;):&#10;                        st.dataframe(pipeline4_result['original_context'])&#10;                with col2:&#10;                    with st.expander(&quot;Show Filtered Context&quot;):&#10;                        if not pipeline4_result['filtered_context'].empty:&#10;                            st.dataframe(pipeline4_result['filtered_context'])&#10;                        else:&#10;                            st.info(&quot;No relevant context found after filtering.&quot;)&#10;&#10;                st.subheader(&quot;Final Answer&quot;)&#10;                st.success(pipeline4_result['answer'])&#10;            else:&#10;                st.warning(&quot;No context could be retrieved for any query in the pool.&quot;)&#10;elif st.session_state.page == 'ranking':&#10;    # --- Ranking Mode ---&#10;    # --- Test Queries ---&#10;    TEST_QUERIES = [&#10;        &quot;What are the health benefits of a Mediterranean diet?&quot;,&#10;        &quot;How does climate change affect coral reefs?&quot;,&#10;        &quot;What is the process of photosynthesis?&quot;,&#10;        &quot;Why is the sky blue?&quot;,&#10;        &quot;What are the main causes of inflation?&quot;,&#10;        &quot;How do vaccines work to prevent diseases?&quot;,&#10;        &quot;What are the effects of exercise on mental health?&quot;,&#10;        &quot;How does artificial intelligence impact job markets?&quot;,&#10;        &quot;What causes earthquakes and how are they measured?&quot;,&#10;        &quot;How do solar panels convert sunlight into electricity?&quot;,&#10;        &quot;What are the benefits and risks of nuclear energy?&quot;,&#10;        &quot;How does the human immune system fight infections?&quot;,&#10;        &quot;What is the role of genetics in determining personality?&quot;,&#10;        &quot;How do hurricanes form and why are they so destructive?&quot;,&#10;        &quot;What are the environmental impacts of fast fashion?&quot;&#10;    ]&#10;&#10;    # --- Initialize Session State for Ranking ---&#10;    if 'results_ready' not in st.session_state:&#10;        st.session_state.results_ready = False&#10;    if 'comparison_results' not in st.session_state:&#10;        st.session_state.comparison_results = []&#10;    if 'current_vote_index' not in st.session_state:&#10;        st.session_state.current_vote_index = 0&#10;    if 'votes' not in st.session_state:&#10;        st.session_state.votes = []&#10;    if 'voting_complete' not in st.session_state:&#10;        st.session_state.voting_complete = False&#10;&#10;    st.title(&quot; RAG Pipeline Comparison Tool&quot;)&#10;    st.markdown(&#10;        &quot;&quot;&quot;&#10;    This application compares Pipeline 1 (Direct Context → Answer) vs Pipeline 4 (Query Pool → Direct Answer).&#10;    Click 'Start Comparison' to run test queries through both pipelines and then vote on the results.&#10;    &quot;&quot;&quot;&#10;    )&#10;&#10;    retriever = get_retriever()&#10;    llm_generator = get_llm_generator()&#10;&#10;    if not retriever or not llm_generator:&#10;        st.warning(&quot;One or more services could not be initialized. The app cannot proceed.&quot;)&#10;        st.stop()&#10;&#10;    # --- Run Comparison ---&#10;    if not st.session_state.results_ready:&#10;        if st.button(&quot;Start Comparison&quot;, type=&quot;primary&quot;):&#10;            st.session_state.comparison_results = []&#10;&#10;            # Progress bar&#10;            progress_bar = st.progress(0)&#10;            status_text = st.empty()&#10;&#10;            for i, query in enumerate(TEST_QUERIES):&#10;                status_text.text(f&quot;Processing query {i+1}/{len(TEST_QUERIES)}: {query[:50]}...&quot;)&#10;&#10;                # Run both pipelines&#10;                pipeline1_result = run_pipeline_1(query, retriever, llm_generator)&#10;                pipeline4_result = run_pipeline_4(query, retriever, llm_generator)&#10;&#10;                # Randomly assign which pipeline goes to left/right&#10;                if random.choice([True, False]):&#10;                    left_result = (&quot;Pipeline 1&quot;, pipeline1_result)&#10;                    right_result = (&quot;Pipeline 4&quot;, pipeline4_result)&#10;                else:&#10;                    left_result = (&quot;Pipeline 4&quot;, pipeline4_result)&#10;                    right_result = (&quot;Pipeline 1&quot;, pipeline1_result)&#10;&#10;                st.session_state.comparison_results.append({&#10;                    'query': query,&#10;                    'left': left_result,&#10;                    'right': right_result,&#10;                    'pipeline1_answer': pipeline1_result['answer'],&#10;                    'pipeline4_answer': pipeline4_result['answer']&#10;                })&#10;&#10;                progress_bar.progress((i + 1) / len(TEST_QUERIES))&#10;&#10;            status_text.text(&quot;✅ All queries processed! Ready for voting.&quot;)&#10;            st.session_state.results_ready = True&#10;            st.rerun()&#10;&#10;    # --- Voting Interface ---&#10;    elif st.session_state.results_ready and not st.session_state.voting_complete:&#10;        st.header(&quot;️ Vote for the Better Answer&quot;)&#10;&#10;        current_idx = st.session_state.current_vote_index&#10;        if current_idx &lt; len(st.session_state.comparison_results):&#10;            result = st.session_state.comparison_results[current_idx]&#10;&#10;            # Progress indicator&#10;            st.progress((current_idx + 1) / len(st.session_state.comparison_results))&#10;            st.text(f&quot;Question {current_idx + 1} of {len(st.session_state.comparison_results)}&quot;)&#10;&#10;            # Display query&#10;            st.subheader(&quot;Query:&quot;)&#10;            st.info(result['query'])&#10;&#10;            # Display answers side by side&#10;            col1, col2 = st.columns(2)&#10;&#10;            with col1:&#10;                st.subheader(&quot;Answer A&quot;)&#10;                st.write(result['left'][1]['answer'])&#10;&#10;            with col2:&#10;                st.subheader(&quot;Answer B&quot;)&#10;                st.write(result['right'][1]['answer'])&#10;&#10;            # Context Viewing Dropdown&#10;            st.markdown(&quot;---&quot;)&#10;            st.subheader(&quot; Context Inspection&quot;)&#10;&#10;            # Get pipeline results for context display&#10;            pipeline1_result = None&#10;            pipeline4_result = None&#10;&#10;            # Determine which pipeline is which&#10;            for name, result_data in [result['left'], result['right']]:&#10;                if name == &quot;Pipeline 1&quot;:&#10;                    pipeline1_result = result_data&#10;                elif name == &quot;Pipeline 4&quot;:&#10;                    pipeline4_result = result_data&#10;&#10;            # Create context view options&#10;            context_options = []&#10;            context_data = {}&#10;&#10;            if pipeline1_result is not None:&#10;                if not pipeline1_result['original_context'].empty:&#10;                    context_options.append(&quot;Pipeline 1 - Original Context&quot;)&#10;                    context_data[&quot;Pipeline 1 - Original Context&quot;] = pipeline1_result['original_context']&#10;&#10;                if not pipeline1_result['filtered_context'].empty:&#10;                    context_options.append(&quot;Pipeline 1 - Filtered Context&quot;)&#10;                    context_data[&quot;Pipeline 1 - Filtered Context&quot;] = pipeline1_result['filtered_context']&#10;&#10;            if pipeline4_result is not None:&#10;                if not pipeline4_result['original_context'].empty:&#10;                    context_options.append(&quot;Pipeline 4 - Original Context&quot;)&#10;                    context_data[&quot;Pipeline 4 - Original Context&quot;] = pipeline4_result['original_context']&#10;&#10;                if not pipeline4_result['filtered_context'].empty:&#10;                    context_options.append(&quot;Pipeline 4 - Filtered Context&quot;)&#10;                    context_data[&quot;Pipeline 4 - Filtered Context&quot;] = pipeline4_result['filtered_context']&#10;&#10;            if context_options:&#10;                selected_context = st.selectbox(&#10;                    &quot;Select context to view:&quot;,&#10;                    options=[&quot;None&quot;] + context_options,&#10;                    index=0&#10;                )&#10;&#10;                if selected_context != &quot;None&quot; and selected_context in context_data:&#10;                    selected_df = context_data[selected_context]&#10;&#10;                    # Display context statistics&#10;                    col1, col2 = st.columns(2)&#10;                    with col1:&#10;                        st.metric(&quot;Number of snippets&quot;, len(selected_df))&#10;                    with col2:&#10;                        if &quot;Pipeline 1&quot; in selected_context and pipeline1_result is not None:&#10;                            original_count = len(pipeline1_result['original_context'])&#10;                            filtered_count = len(pipeline1_result['filtered_context'])&#10;                            if &quot;Filtered&quot; in selected_context and original_count &gt; 0:&#10;                                retention_rate = (filtered_count / original_count) * 100&#10;                                st.metric(&quot;Retention rate&quot;, f&quot;{retention_rate:.1f}%&quot;)&#10;                        elif &quot;Pipeline 4&quot; in selected_context and pipeline4_result is not None:&#10;                            original_count = len(pipeline4_result['original_context'])&#10;                            filtered_count = len(pipeline4_result['filtered_context'])&#10;                            if &quot;Filtered&quot; in selected_context and original_count &gt; 0:&#10;                                retention_rate = (filtered_count / original_count) * 100&#10;                                st.metric(&quot;Retention rate&quot;, f&quot;{retention_rate:.1f}%&quot;)&#10;&#10;                    # Display context snippets&#10;                    with st.expander(f&quot;View {selected_context} snippets&quot;, expanded=True):&#10;                        for idx, row in selected_df.iterrows():&#10;                            st.markdown(f&quot;**Snippet {idx + 1}:**&quot;)&#10;                            st.text(row['text'])&#10;                            st.markdown(&quot;---&quot;)&#10;            else:&#10;                st.info(&quot;No context available for this query.&quot;)&#10;&#10;            # Voting buttons&#10;            st.markdown(&quot;---&quot;)&#10;            col1, col2, col3 = st.columns(3)&#10;&#10;            with col1:&#10;                if st.button(&quot; Answer A is Better&quot;, use_container_width=True):&#10;                    winner = result['left'][0]  # Pipeline name&#10;                    st.session_state.votes.append({&#10;                        'query': result['query'],&#10;                        'output_1': result['pipeline1_answer'],&#10;                        'output_2': result['pipeline4_answer'],&#10;                        'winner': winner&#10;                    })&#10;                    st.session_state.current_vote_index += 1&#10;                    st.rerun()&#10;&#10;            with col2:&#10;                if st.button(&quot; Don't Care&quot;, use_container_width=True):&#10;                    st.session_state.votes.append({&#10;                        'query': result['query'],&#10;                        'output_1': result['pipeline1_answer'],&#10;                        'output_2': result['pipeline4_answer'],&#10;                        'winner': 'Don\'t Care'&#10;                    })&#10;                    st.session_state.current_vote_index += 1&#10;                    st.rerun()&#10;&#10;            with col3:&#10;                if st.button(&quot; Answer B is Better&quot;, use_container_width=True):&#10;                    winner = result['right'][0]  # Pipeline name&#10;                    st.session_state.votes.append({&#10;                        'query': result['query'],&#10;                        'output_1': result['pipeline1_answer'],&#10;                        'output_2': result['pipeline4_answer'],&#10;                        'winner': winner&#10;                    })&#10;                    st.session_state.current_vote_index += 1&#10;                    st.rerun()&#10;&#10;        else:&#10;            st.session_state.voting_complete = True&#10;            st.rerun()&#10;&#10;    # --- Results and Export ---&#10;    elif st.session_state.voting_complete:&#10;        st.header(&quot; Voting Complete!&quot;)&#10;&#10;        # Display results summary&#10;        votes_df = pd.DataFrame(st.session_state.votes)&#10;&#10;        st.subheader(&quot;Results Summary&quot;)&#10;        pipeline1_wins = len(votes_df[votes_df['winner'] == 'Pipeline 1'])&#10;        pipeline4_wins = len(votes_df[votes_df['winner'] == 'Pipeline 4'])&#10;        dont_care = len(votes_df[votes_df['winner'] == 'Don\'t Care'])&#10;&#10;        col1, col2, col3 = st.columns(3)&#10;        with col1:&#10;            st.metric(&quot;Pipeline 1 Wins&quot;, pipeline1_wins)&#10;        with col2:&#10;            st.metric(&quot;Pipeline 4 Wins&quot;, pipeline4_wins)&#10;        with col3:&#10;            st.metric(&quot;Don't Care&quot;, dont_care)&#10;&#10;        # Export functionality&#10;        st.subheader(&quot;Export Results&quot;)&#10;&#10;        # Create CSV content&#10;        csv_buffer = io.StringIO()&#10;        votes_df.to_csv(csv_buffer, index=False)&#10;        csv_content = csv_buffer.getvalue()&#10;&#10;        st.download_button(&#10;            label=&quot; Download Results as CSV&quot;,&#10;            data=csv_content,&#10;            file_name=&quot;pipeline_comparison_results.csv&quot;,&#10;            mime=&quot;text/csv&quot;&#10;        )&#10;&#10;        # Display detailed results&#10;        with st.expander(&quot;View Detailed Results&quot;):&#10;            st.dataframe(votes_df)&#10;&#10;        # Reset button&#10;        if st.button(&quot; Start New Comparison&quot;):&#10;            st.session_state.results_ready = False&#10;            st.session_state.comparison_results = []&#10;            st.session_state.current_vote_index = 0&#10;            st.session_state.votes = []&#10;            st.session_state.voting_complete = False&#10;            st.rerun()&#10;" />
              <option name="updatedContent" value="import streamlit as st&#10;import pandas as pd&#10;from SourceRetriever import SourceRetriever&#10;from LLM import LLM&#10;from dotenv import dotenv_values&#10;&#10;# --- Page Configuration ---&#10;st.set_page_config(&#10;    page_title=&quot;RAG Pipeline Analysis Tool&quot;,&#10;    page_icon=&quot;&quot;,&#10;    layout=&quot;wide&quot;&#10;)&#10;&#10;# --- Pipeline Functions ---&#10;def run_pipeline_1(query, retriever, llm_generator):&#10;    &quot;&quot;&quot;Pipeline 1: Original Query (Direct Context → Filter → Answer)&quot;&quot;&quot;&#10;    try:&#10;        context_df = retriever.get_context(query)&#10;        original_context = context_df.copy() if not context_df.empty else pd.DataFrame()&#10;&#10;        if not context_df.empty:&#10;            # Apply context filtering for Pipeline 1&#10;            filtered_context_df = llm_generator.filter_context(context_df, query)&#10;&#10;            if not filtered_context_df.empty:&#10;                answer = llm_generator.answer_question_from_context(filtered_context_df, query)&#10;                return {&#10;                    'answer': answer or &quot;Could not generate an answer.&quot;,&#10;                    'original_context': original_context,&#10;                    'filtered_context': filtered_context_df&#10;                }&#10;            else:&#10;                return {&#10;                    'answer': &quot;No relevant context found for this query.&quot;,&#10;                    'original_context': original_context,&#10;                    'filtered_context': pd.DataFrame()&#10;                }&#10;        return {&#10;            'answer': &quot;No context retrieved.&quot;,&#10;            'original_context': pd.DataFrame(),&#10;            'filtered_context': pd.DataFrame()&#10;        }&#10;    except Exception as e:&#10;        return {&#10;            'answer': f&quot;Error in Pipeline 1: {str(e)}&quot;,&#10;            'original_context': pd.DataFrame(),&#10;            'filtered_context': pd.DataFrame()&#10;        }&#10;&#10;def run_pipeline_2(query, retriever, llm_generator):&#10;    &quot;&quot;&quot;Pipeline 2: Original Query (Summary → Answer)&quot;&quot;&quot;&#10;    try:&#10;        context_df = retriever.get_context(query)&#10;&#10;        if not context_df.empty:&#10;            summarized_context = llm_generator.summarize_context(context_df, query)&#10;            if summarized_context:&#10;                answer = llm_generator.answer_question_from_summary(summarized_context, query)&#10;                return {&#10;                    'answer': answer or &quot;Could not generate an answer.&quot;,&#10;                    'context': context_df,&#10;                    'summary': summarized_context&#10;                }&#10;        return {&#10;            'answer': &quot;No context retrieved.&quot;,&#10;            'context': pd.DataFrame(),&#10;            'summary': &quot;&quot;&#10;        }&#10;    except Exception as e:&#10;        return {&#10;            'answer': f&quot;Error in Pipeline 2: {str(e)}&quot;,&#10;            'context': pd.DataFrame(),&#10;            'summary': &quot;&quot;&#10;        }&#10;&#10;def run_pipeline_3(query, retriever, llm_generator):&#10;    &quot;&quot;&quot;Pipeline 3: Rewritten Query (Rewrite → Summary → Answer)&quot;&quot;&quot;&#10;    try:&#10;        rewritten_query = llm_generator.rewrite_query(query)&#10;        context_df = retriever.get_context(rewritten_query)&#10;&#10;        if not context_df.empty:&#10;            summarized_context = llm_generator.summarize_context(context_df, query)&#10;            if summarized_context:&#10;                answer = llm_generator.answer_question_from_summary(summarized_context, query)&#10;                return {&#10;                    'answer': answer or &quot;Could not generate an answer.&quot;,&#10;                    'rewritten_query': rewritten_query,&#10;                    'context': context_df,&#10;                    'summary': summarized_context&#10;                }&#10;        return {&#10;            'answer': &quot;No context retrieved for rewritten query.&quot;,&#10;            'rewritten_query': rewritten_query,&#10;            'context': pd.DataFrame(),&#10;            'summary': &quot;&quot;&#10;        }&#10;    except Exception as e:&#10;        return {&#10;            'answer': f&quot;Error in Pipeline 3: {str(e)}&quot;,&#10;            'rewritten_query': query,&#10;            'context': pd.DataFrame(),&#10;            'summary': &quot;&quot;&#10;        }&#10;&#10;def run_pipeline_4(query, retriever, llm_generator):&#10;    &quot;&quot;&quot;Pipeline 4: Query Pool (Query Pool → Filtered Context → Direct Answer)&quot;&quot;&quot;&#10;    try:&#10;        query_pool = llm_generator.generate_query_pool(query, 4)&#10;        all_contexts = []&#10;        for q in query_pool:&#10;            pooled_df = retriever.get_context(q)&#10;            if not pooled_df.empty:&#10;                all_contexts.append(pooled_df)&#10;&#10;        if all_contexts:&#10;            full_context_df = pd.concat(all_contexts, ignore_index=True).drop_duplicates(&#10;                subset=['text']).reset_index(drop=True)&#10;            truncated_pool_df = full_context_df.head(100)&#10;            original_context = truncated_pool_df.copy()&#10;&#10;            # Apply context filtering for Pipeline 4&#10;            filtered_context_df = llm_generator.filter_context(truncated_pool_df, query)&#10;&#10;            if not filtered_context_df.empty:&#10;                answer = llm_generator.answer_question_from_context(filtered_context_df, query)&#10;                return {&#10;                    'answer': answer or &quot;Could not generate an answer.&quot;,&#10;                    'query_pool': query_pool,&#10;                    'original_context': original_context,&#10;                    'filtered_context': filtered_context_df&#10;                }&#10;            else:&#10;                return {&#10;                    'answer': &quot;No relevant context found for this query.&quot;,&#10;                    'query_pool': query_pool,&#10;                    'original_context': original_context,&#10;                    'filtered_context': pd.DataFrame()&#10;                }&#10;        return {&#10;            'answer': &quot;No context retrieved from query pool.&quot;,&#10;            'query_pool': query_pool,&#10;            'original_context': pd.DataFrame(),&#10;            'filtered_context': pd.DataFrame()&#10;        }&#10;    except Exception as e:&#10;        return {&#10;            'answer': f&quot;Error in Pipeline 4: {str(e)}&quot;,&#10;            'query_pool': [],&#10;            'original_context': pd.DataFrame(),&#10;            'filtered_context': pd.DataFrame()&#10;        }&#10;&#10;# --- Load API Keys ---&#10;@st.cache_data&#10;def load_config():&#10;    try:&#10;        config = dotenv_values(&quot;.env&quot;)&#10;        es_api_key = config.get(&quot;ES_API_KEY&quot;)&#10;        llm_api_key = config.get(&quot;API_KEY&quot;)&#10;        if not es_api_key or not llm_api_key:&#10;            st.error(&#10;                &quot;API keys (ES_API_KEY, API_KEY) not found in your .env file. Please make sure it's configured correctly.&quot;)&#10;            return None, None&#10;        return es_api_key, llm_api_key&#10;    except Exception as e:&#10;        st.error(f&quot;Could not load the .env file. Please make sure it exists in the root directory. Error: {e}&quot;)&#10;        return None, None&#10;&#10;ES_API_KEY, LLM_API_KEY = load_config()&#10;&#10;if not ES_API_KEY or not LLM_API_KEY:&#10;    st.stop()&#10;&#10;# --- Caching the Clients ---&#10;@st.cache_resource&#10;def get_retriever():&#10;    retriever = SourceRetriever(&#10;        host=&quot;https://elasticsearch.bw.webis.de:9200&quot;,&#10;        api_key=ES_API_KEY,&#10;        serps_index=&quot;aql_serps&quot;,&#10;        results_index=&quot;aql_results&quot;&#10;    )&#10;    if not retriever.es_client:&#10;        st.error(&quot;Failed to connect to Elasticsearch. Please check your VPN and API key.&quot;)&#10;        return None&#10;    return retriever&#10;&#10;@st.cache_resource&#10;def get_llm_generator():&#10;    llm = LLM(&#10;        api_key=LLM_API_KEY,&#10;        base_url=&quot;https://api.helmholtz-blablador.fz-juelich.de/v1/&quot;,&#10;        model=&quot;alias-fast-experimental&quot;&#10;    )&#10;    if not llm.client:&#10;        st.error(&quot;Failed to initialize the LLM client. Please check your API key.&quot;)&#10;        return None&#10;    return llm&#10;&#10;# --- Main Analysis Tool ---&#10;st.title(&quot; RAG Pipeline Analysis Tool&quot;)&#10;st.markdown(&#10;    &quot;&quot;&quot;&#10;This application allows you to test and compare different Retrieval-Augmented Generation (RAG) strategies. &#10;Enter a question below and click 'Run Analysis' to see how each pipeline performs.&#10;&quot;&quot;&quot;&#10;)&#10;&#10;retriever = get_retriever()&#10;llm_generator = get_llm_generator()&#10;&#10;if not retriever or not llm_generator:&#10;    st.warning(&quot;One or more services could not be initialized. The app cannot proceed.&quot;)&#10;    st.stop()&#10;&#10;user_question = st.text_input(&#10;    &quot;Enter your question here:&quot;,&#10;    &quot;Seven Wonders of the World&quot;&#10;)&#10;&#10;if st.button(&quot;Run Analysis&quot;, type=&quot;primary&quot;):&#10;    if not user_question:&#10;        st.warning(&quot;Please enter a question.&quot;)&#10;    else:&#10;        st.success(f&quot;Processing query: **{user_question}**&quot;)&#10;&#10;        # --- Pipeline 1: Original Query (Direct Context → Filter → Answer) ---&#10;        st.header(&quot;Pipeline 1: Original Query (Direct Context → Filter → Answer)&quot;)&#10;        with st.spinner(&quot;Running Pipeline 1...&quot;):&#10;            pipeline1_result = run_pipeline_1(user_question, retriever, llm_generator)&#10;&#10;        if not pipeline1_result['original_context'].empty:&#10;            st.info(f&quot;Retrieved **{len(pipeline1_result['original_context'])}** snippets, filtered to **{len(pipeline1_result['filtered_context'])}** relevant snippets.&quot;)&#10;&#10;            col1, col2 = st.columns(2)&#10;            with col1:&#10;                with st.expander(&quot;Show Original Context&quot;):&#10;                    st.dataframe(pipeline1_result['original_context'])&#10;            with col2:&#10;                with st.expander(&quot;Show Filtered Context&quot;):&#10;                    if not pipeline1_result['filtered_context'].empty:&#10;                        st.dataframe(pipeline1_result['filtered_context'])&#10;                    else:&#10;                        st.info(&quot;No relevant context found after filtering.&quot;)&#10;&#10;            st.subheader(&quot;Final Answer&quot;)&#10;            st.success(pipeline1_result['answer'])&#10;        else:&#10;            st.warning(&quot;No context was retrieved for Pipeline 1.&quot;)&#10;&#10;        # --- Pipeline 2: Original Query (Summary → Answer) ---&#10;        st.header(&quot;Pipeline 2: Original Query (Summary → Answer)&quot;)&#10;        with st.spinner(&quot;Running Pipeline 2...&quot;):&#10;            pipeline2_result = run_pipeline_2(user_question, retriever, llm_generator)&#10;&#10;        if not pipeline2_result['context'].empty:&#10;            st.info(f&quot;Retrieved **{len(pipeline2_result['context'])}** snippets for Pipeline 2.&quot;)&#10;            with st.expander(&quot;Show Retrieved Context for Pipeline 2&quot;):&#10;                st.dataframe(pipeline2_result['context'])&#10;&#10;            with st.expander(&quot;Show Pipeline 2 Result&quot;):&#10;                st.subheader(&quot;Intermediate Summary&quot;)&#10;                st.write(pipeline2_result['summary'] or &quot;Could not generate summary.&quot;)&#10;                st.subheader(&quot;Final Answer&quot;)&#10;                st.success(pipeline2_result['answer'])&#10;        else:&#10;            st.warning(&quot;No context was retrieved for Pipeline 2.&quot;)&#10;&#10;        # --- Pipeline 3: Rewritten Query (Rewrite → Summary → Answer) ---&#10;        st.header(&quot;Pipeline 3: Rewritten Query (Rewrite → Summary → Answer)&quot;)&#10;        with st.spinner(&quot;Running Pipeline 3...&quot;):&#10;            pipeline3_result = run_pipeline_3(user_question, retriever, llm_generator)&#10;&#10;        st.subheader(&quot;LLM-Rewritten Query&quot;)&#10;        st.info(f&quot;**{pipeline3_result['rewritten_query']}**&quot;)&#10;&#10;        if not pipeline3_result['context'].empty:&#10;            st.info(f&quot;Retrieved **{len(pipeline3_result['context'])}** snippets for Pipeline 3.&quot;)&#10;            with st.expander(&quot;Show Retrieved Context for Pipeline 3&quot;):&#10;                st.dataframe(pipeline3_result['context'])&#10;&#10;            with st.expander(&quot;Show Pipeline 3 Result&quot;):&#10;                st.subheader(&quot;Intermediate Summary&quot;)&#10;                st.write(pipeline3_result['summary'] or &quot;Could not generate summary.&quot;)&#10;                st.subheader(&quot;Final Answer&quot;)&#10;                st.success(pipeline3_result['answer'])&#10;        else:&#10;            st.warning(&quot;No context was retrieved for Pipeline 3.&quot;)&#10;&#10;        # --- Pipeline 4: Query Pool (Query Pool → Filtered Context → Direct Answer) ---&#10;        st.header(&quot;Pipeline 4: Query Pool (Query Pool → Filtered Context → Direct Answer)&quot;)&#10;        with st.spinner(&quot;Running Pipeline 4...&quot;):&#10;            pipeline4_result = run_pipeline_4(user_question, retriever, llm_generator)&#10;&#10;        if pipeline4_result['query_pool']:&#10;            st.subheader(&quot;Generated Query Pool&quot;)&#10;            for i, query in enumerate(pipeline4_result['query_pool'], 1):&#10;                st.write(f&quot;{i}. {query}&quot;)&#10;&#10;        if not pipeline4_result['original_context'].empty:&#10;            st.info(f&quot;Retrieved **{len(pipeline4_result['original_context'])}** total unique snippets, filtered to **{len(pipeline4_result['filtered_context'])}** relevant snippets.&quot;)&#10;&#10;            col1, col2 = st.columns(2)&#10;            with col1:&#10;                with st.expander(&quot;Show Original Pooled Context&quot;):&#10;                    st.dataframe(pipeline4_result['original_context'])&#10;            with col2:&#10;                with st.expander(&quot;Show Filtered Context&quot;):&#10;                    if not pipeline4_result['filtered_context'].empty:&#10;                        st.dataframe(pipeline4_result['filtered_context'])&#10;                    else:&#10;                        st.info(&quot;No relevant context found after filtering.&quot;)&#10;&#10;            st.subheader(&quot;Final Answer&quot;)&#10;            st.success(pipeline4_result['answer'])&#10;        else:&#10;            st.warning(&quot;No context could be retrieved for any query in the pool.&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/app_rank.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app_rank.py" />
              <option name="originalContent" value="import streamlit as st&#10;import pandas as pd&#10;from SourceRetriever import SourceRetriever&#10;from LLM import LLM&#10;from dotenv import dotenv_values&#10;import random&#10;import io&#10;import subprocess&#10;import sys&#10;&#10;# --- Page Configuration ---&#10;st.set_page_config(&#10;    page_title=&quot;RAG Pipeline Comparison Tool&quot;,&#10;    page_icon=&quot;&quot;,&#10;    layout=&quot;wide&quot;&#10;)&#10;&#10;# --- Navigation ---&#10;col1, col2 = st.columns([4, 1])&#10;with col2:&#10;    if st.button(&quot; Back to Analysis Tool&quot;, use_container_width=True):&#10;        # Launch the main app in a new process&#10;        subprocess.Popen([sys.executable, &quot;-m&quot;, &quot;streamlit&quot;, &quot;run&quot;, &quot;app.py&quot;, &quot;--server.port&quot;, &quot;8501&quot;])&#10;        st.info(&quot;Analysis app öffnet sich in einem neuen Tab auf Port 8501&quot;)&#10;&#10;# --- Load API Keys ---&#10;@st.cache_data&#10;def load_config():&#10;    try:&#10;        config = dotenv_values(&quot;.env&quot;)&#10;        es_api_key = config.get(&quot;ES_API_KEY&quot;)&#10;        llm_api_key = config.get(&quot;API_KEY&quot;)&#10;        if not es_api_key or not llm_api_key:&#10;            st.error(&#10;                &quot;API keys (ES_API_KEY, API_KEY) not found in your .env file. Please make sure it's configured correctly.&quot;)&#10;            return None, None&#10;        return es_api_key, llm_api_key&#10;    except Exception as e:&#10;        st.error(f&quot;Could not load the .env file. Please make sure it exists in the root directory. Error: {e}&quot;)&#10;        return None, None&#10;&#10;ES_API_KEY, LLM_API_KEY = load_config()&#10;&#10;if not ES_API_KEY or not LLM_API_KEY:&#10;    st.stop()&#10;&#10;# --- Caching the Clients ---&#10;@st.cache_resource&#10;def get_retriever():&#10;    retriever = SourceRetriever(&#10;        host=&quot;https://elasticsearch.bw.webis.de:9200&quot;,&#10;        api_key=ES_API_KEY,&#10;        serps_index=&quot;aql_serps&quot;,&#10;        results_index=&quot;aql_results&quot;&#10;    )&#10;    if not retriever.es_client:&#10;        st.error(&quot;Failed to connect to Elasticsearch. Please check your VPN and API key.&quot;)&#10;        return None&#10;    return retriever&#10;&#10;@st.cache_resource&#10;def get_llm_generator():&#10;    llm = LLM(&#10;        api_key=LLM_API_KEY,&#10;        base_url=&quot;https://api.helmholtz-blablador.fz-juelich.de/v1/&quot;,&#10;        model=&quot;alias-fast&quot;&#10;    )&#10;    if not llm.client:&#10;        st.error(&quot;Failed to initialize the LLM client. Please check your API key.&quot;)&#10;        return None&#10;    return llm&#10;&#10;# --- Test Queries ---&#10;TEST_QUERIES = [&#10;    &quot;What are the health benefits of a Mediterranean diet?&quot;,&#10;    &quot;How does climate change affect coral reefs?&quot;,&#10;    &quot;What is the process of photosynthesis?&quot;,&#10;    &quot;Why is the sky blue?&quot;,&#10;    &quot;What are the main causes of inflation?&quot;,&#10;    &quot;How do vaccines work to prevent diseases?&quot;,&#10;    &quot;What are the effects of exercise on mental health?&quot;,&#10;    &quot;How does artificial intelligence impact job markets?&quot;,&#10;    &quot;What causes earthquakes and how are they measured?&quot;,&#10;    &quot;How do solar panels convert sunlight into electricity?&quot;,&#10;    &quot;What are the benefits and risks of nuclear energy?&quot;,&#10;    &quot;How does the human immune system fight infections?&quot;,&#10;    &quot;What is the role of genetics in determining personality?&quot;,&#10;    &quot;How do hurricanes form and why are they so destructive?&quot;,&#10;    &quot;What are the environmental impacts of fast fashion?&quot;&#10;]&#10;&#10;# --- Pipeline Functions ---&#10;def run_pipeline_1(query, retriever, llm_generator):&#10;    &quot;&quot;&quot;Pipeline 1: Original Query (Direct Context → Filter → Answer)&quot;&quot;&quot;&#10;    try:&#10;        context_df = retriever.get_context(query)&#10;        original_context = context_df.copy() if not context_df.empty else pd.DataFrame()&#10;&#10;        if not context_df.empty:&#10;            # Apply context filtering for Pipeline 1&#10;            filtered_context_df = llm_generator.filter_context(context_df, query)&#10;&#10;            if not filtered_context_df.empty:&#10;                answer = llm_generator.answer_question_from_context(filtered_context_df, query)&#10;                return {&#10;                    'answer': answer or &quot;Could not generate an answer.&quot;,&#10;                    'original_context': original_context,&#10;                    'filtered_context': filtered_context_df&#10;                }&#10;            else:&#10;                return {&#10;                    'answer': &quot;No relevant context found for this query.&quot;,&#10;                    'original_context': original_context,&#10;                    'filtered_context': pd.DataFrame()&#10;                }&#10;        return {&#10;            'answer': &quot;No context retrieved.&quot;,&#10;            'original_context': pd.DataFrame(),&#10;            'filtered_context': pd.DataFrame()&#10;        }&#10;    except Exception as e:&#10;        return {&#10;            'answer': f&quot;Error in Pipeline 1: {str(e)}&quot;,&#10;            'original_context': pd.DataFrame(),&#10;            'filtered_context': pd.DataFrame()&#10;        }&#10;&#10;def run_pipeline_4(query, retriever, llm_generator):&#10;    &quot;&quot;&quot;Pipeline 4: Query Pool (Query Pool → Filtered Context → Direct Answer)&quot;&quot;&quot;&#10;    try:&#10;        query_pool = llm_generator.generate_query_pool(query, 10)&#10;        all_contexts = []&#10;        for q in query_pool:&#10;            pooled_df = retriever.get_context(q)&#10;            if not pooled_df.empty:&#10;                all_contexts.append(pooled_df)&#10;&#10;        if all_contexts:&#10;            full_context_df = pd.concat(all_contexts, ignore_index=True).drop_duplicates(&#10;                subset=['text']).reset_index(drop=True)&#10;            truncated_pool_df = full_context_df.head(100)&#10;            original_context = truncated_pool_df.copy()&#10;&#10;            # Apply context filtering for Pipeline 4&#10;            filtered_context_df = llm_generator.filter_context(truncated_pool_df, query)&#10;&#10;            if not filtered_context_df.empty:&#10;                answer = llm_generator.answer_question_from_context(filtered_context_df, query)&#10;                return {&#10;                    'answer': answer or &quot;Could not generate an answer.&quot;,&#10;                    'original_context': original_context,&#10;                    'filtered_context': filtered_context_df&#10;                }&#10;            else:&#10;                return {&#10;                    'answer': &quot;No relevant context found for this query.&quot;,&#10;                    'original_context': original_context,&#10;                    'filtered_context': pd.DataFrame()&#10;                }&#10;        return {&#10;            'answer': &quot;No context retrieved from query pool.&quot;,&#10;            'original_context': pd.DataFrame(),&#10;            'filtered_context': pd.DataFrame()&#10;        }&#10;    except Exception as e:&#10;        return {&#10;            'answer': f&quot;Error in Pipeline 4: {str(e)}&quot;,&#10;            'original_context': pd.DataFrame(),&#10;            'filtered_context': pd.DataFrame()&#10;        }&#10;&#10;# --- Initialize Session State ---&#10;if 'results_ready' not in st.session_state:&#10;    st.session_state.results_ready = False&#10;if 'comparison_results' not in st.session_state:&#10;    st.session_state.comparison_results = []&#10;if 'current_vote_index' not in st.session_state:&#10;    st.session_state.current_vote_index = 0&#10;if 'votes' not in st.session_state:&#10;    st.session_state.votes = []&#10;if 'voting_complete' not in st.session_state:&#10;    st.session_state.voting_complete = False&#10;&#10;# --- Main App UI ---&#10;st.title(&quot; RAG Pipeline Comparison Tool&quot;)&#10;st.markdown(&#10;    &quot;&quot;&quot;&#10;This application compares Pipeline 1 (Direct Context → Answer) vs Pipeline 4 (Query Pool → Direct Answer).&#10;Click 'Start Comparison' to run 15 test queries through both pipelines and then vote on the results.&#10;&quot;&quot;&quot;&#10;)&#10;&#10;retriever = get_retriever()&#10;llm_generator = get_llm_generator()&#10;&#10;if not retriever or not llm_generator:&#10;    st.warning(&quot;One or more services could not be initialized. The app cannot proceed.&quot;)&#10;    st.stop()&#10;&#10;# --- Run Comparison ---&#10;if not st.session_state.results_ready:&#10;    if st.button(&quot;Start Comparison&quot;, type=&quot;primary&quot;):&#10;        st.session_state.comparison_results = []&#10;&#10;        # Progress bar&#10;        progress_bar = st.progress(0)&#10;        status_text = st.empty()&#10;&#10;        for i, query in enumerate(TEST_QUERIES):&#10;            status_text.text(f&quot;Processing query {i+1}/15: {query}&quot;)&#10;&#10;            # Run both pipelines&#10;            pipeline1_result = run_pipeline_1(query, retriever, llm_generator)&#10;            pipeline4_result = run_pipeline_4(query, retriever, llm_generator)&#10;&#10;            # Randomly assign which pipeline goes to left/right&#10;            if random.choice([True, False]):&#10;                left_result = (&quot;Pipeline 1&quot;, pipeline1_result)&#10;                right_result = (&quot;Pipeline 4&quot;, pipeline4_result)&#10;            else:&#10;                left_result = (&quot;Pipeline 4&quot;, pipeline4_result)&#10;                right_result = (&quot;Pipeline 1&quot;, pipeline1_result)&#10;&#10;            st.session_state.comparison_results.append({&#10;                'query': query,&#10;                'left': left_result,&#10;                'right': right_result,&#10;                'pipeline1_answer': pipeline1_result['answer'],&#10;                'pipeline4_answer': pipeline4_result['answer']&#10;            })&#10;&#10;            progress_bar.progress((i + 1) / len(TEST_QUERIES))&#10;&#10;        status_text.text(&quot;✅ All queries processed! Ready for voting.&quot;)&#10;        st.session_state.results_ready = True&#10;        st.rerun()&#10;&#10;# --- Voting Interface ---&#10;elif st.session_state.results_ready and not st.session_state.voting_complete:&#10;    st.header(&quot;️ Vote for the Better Answer&quot;)&#10;&#10;    current_idx = st.session_state.current_vote_index&#10;    if current_idx &lt; len(st.session_state.comparison_results):&#10;        result = st.session_state.comparison_results[current_idx]&#10;&#10;        # Progress indicator&#10;        st.progress((current_idx + 1) / len(st.session_state.comparison_results))&#10;        st.text(f&quot;Question {current_idx + 1} of {len(st.session_state.comparison_results)}&quot;)&#10;&#10;        # Display query&#10;        st.subheader(&quot;Query:&quot;)&#10;        st.info(result['query'])&#10;&#10;        # Display answers side by side&#10;        col1, col2 = st.columns(2)&#10;&#10;        with col1:&#10;            st.subheader(&quot;Answer A&quot;)&#10;            st.write(result['left'][1]['answer'])&#10;&#10;        with col2:&#10;            st.subheader(&quot;Answer B&quot;)&#10;            st.write(result['right'][1]['answer'])&#10;&#10;        # Context Viewing Dropdown&#10;        st.markdown(&quot;---&quot;)&#10;        st.subheader(&quot; Context Inspection&quot;)&#10;&#10;        # Get pipeline results for context display&#10;        pipeline1_result = None&#10;        pipeline4_result = None&#10;&#10;        # Determine which pipeline is which&#10;        for name, result_data in [result['left'], result['right']]:&#10;            if name == &quot;Pipeline 1&quot;:&#10;                pipeline1_result = result_data&#10;            elif name == &quot;Pipeline 4&quot;:&#10;                pipeline4_result = result_data&#10;&#10;        # Create context view options&#10;        context_options = []&#10;        context_data = {}&#10;&#10;        if pipeline1_result is not None:&#10;            if not pipeline1_result['original_context'].empty:&#10;                context_options.append(&quot;Pipeline 1 - Original Context&quot;)&#10;                context_data[&quot;Pipeline 1 - Original Context&quot;] = pipeline1_result['original_context']&#10;&#10;            if not pipeline1_result['filtered_context'].empty:&#10;                context_options.append(&quot;Pipeline 1 - Filtered Context&quot;)&#10;                context_data[&quot;Pipeline 1 - Filtered Context&quot;] = pipeline1_result['filtered_context']&#10;&#10;        if pipeline4_result is not None:&#10;            if not pipeline4_result['original_context'].empty:&#10;                context_options.append(&quot;Pipeline 4 - Original Context&quot;)&#10;                context_data[&quot;Pipeline 4 - Original Context&quot;] = pipeline4_result['original_context']&#10;&#10;            if not pipeline4_result['filtered_context'].empty:&#10;                context_options.append(&quot;Pipeline 4 - Filtered Context&quot;)&#10;                context_data[&quot;Pipeline 4 - Filtered Context&quot;] = pipeline4_result['filtered_context']&#10;&#10;        if context_options:&#10;            selected_context = st.selectbox(&#10;                &quot;Select context to view:&quot;,&#10;                options=[&quot;None&quot;] + context_options,&#10;                index=0&#10;            )&#10;&#10;            if selected_context != &quot;None&quot; and selected_context in context_data:&#10;                selected_df = context_data[selected_context]&#10;&#10;                # Display context statistics&#10;                col1, col2 = st.columns(2)&#10;                with col1:&#10;                    st.metric(&quot;Number of snippets&quot;, len(selected_df))&#10;                with col2:&#10;                    if &quot;Pipeline 1&quot; in selected_context and pipeline1_result is not None:&#10;                        original_count = len(pipeline1_result['original_context'])&#10;                        filtered_count = len(pipeline1_result['filtered_context'])&#10;                        if &quot;Filtered&quot; in selected_context and original_count &gt; 0:&#10;                            retention_rate = (filtered_count / original_count) * 100&#10;                            st.metric(&quot;Retention rate&quot;, f&quot;{retention_rate:.1f}%&quot;)&#10;                    elif &quot;Pipeline 4&quot; in selected_context and pipeline4_result is not None:&#10;                        original_count = len(pipeline4_result['original_context'])&#10;                        filtered_count = len(pipeline4_result['filtered_context'])&#10;                        if &quot;Filtered&quot; in selected_context and original_count &gt; 0:&#10;                            retention_rate = (filtered_count / original_count) * 100&#10;                            st.metric(&quot;Retention rate&quot;, f&quot;{retention_rate:.1f}%&quot;)&#10;&#10;                # Display context snippets&#10;                with st.expander(f&quot;View {selected_context} snippets&quot;, expanded=True):&#10;                    for idx, row in selected_df.iterrows():&#10;                        st.markdown(f&quot;**Snippet {idx + 1}:**&quot;)&#10;                        st.text(row['text'])&#10;                        st.markdown(&quot;---&quot;)&#10;        else:&#10;            st.info(&quot;No context available for this query.&quot;)&#10;&#10;        # Voting buttons&#10;        st.markdown(&quot;---&quot;)&#10;        col1, col2, col3 = st.columns(3)&#10;&#10;        with col1:&#10;            if st.button(&quot; Answer A is Better&quot;, use_container_width=True):&#10;                winner = result['left'][0]  # Pipeline name&#10;                st.session_state.votes.append({&#10;                    'query': result['query'],&#10;                    'output_1': result['pipeline1_answer'],&#10;                    'output_2': result['pipeline4_answer'],&#10;                    'winner': winner&#10;                })&#10;                st.session_state.current_vote_index += 1&#10;                st.rerun()&#10;&#10;        with col2:&#10;            if st.button(&quot; Don't Care&quot;, use_container_width=True):&#10;                st.session_state.votes.append({&#10;                    'query': result['query'],&#10;                    'output_1': result['pipeline1_answer'],&#10;                    'output_2': result['pipeline4_answer'],&#10;                    'winner': 'Don\'t Care'&#10;                })&#10;                st.session_state.current_vote_index += 1&#10;                st.rerun()&#10;&#10;        with col3:&#10;            if st.button(&quot; Answer B is Better&quot;, use_container_width=True):&#10;                winner = result['right'][0]  # Pipeline name&#10;                st.session_state.votes.append({&#10;                    'query': result['query'],&#10;                    'output_1': result['pipeline1_answer'],&#10;                    'output_2': result['pipeline4_answer'],&#10;                    'winner': winner&#10;                })&#10;                st.session_state.current_vote_index += 1&#10;                st.rerun()&#10;&#10;    else:&#10;        st.session_state.voting_complete = True&#10;        st.rerun()&#10;&#10;# --- Results and Export ---&#10;elif st.session_state.voting_complete:&#10;    st.header(&quot; Voting Complete!&quot;)&#10;&#10;    # Display results summary&#10;    votes_df = pd.DataFrame(st.session_state.votes)&#10;&#10;    st.subheader(&quot;Results Summary&quot;)&#10;    pipeline1_wins = len(votes_df[votes_df['winner'] == 'Pipeline 1'])&#10;    pipeline4_wins = len(votes_df[votes_df['winner'] == 'Pipeline 4'])&#10;    dont_care = len(votes_df[votes_df['winner'] == 'Don\'t Care'])&#10;&#10;    col1, col2, col3 = st.columns(3)&#10;    with col1:&#10;        st.metric(&quot;Pipeline 1 Wins&quot;, pipeline1_wins)&#10;    with col2:&#10;        st.metric(&quot;Pipeline 4 Wins&quot;, pipeline4_wins)&#10;    with col3:&#10;        st.metric(&quot;Don't Care&quot;, dont_care)&#10;&#10;    # Export functionality&#10;    st.subheader(&quot;Export Results&quot;)&#10;&#10;    # Create CSV content&#10;    csv_buffer = io.StringIO()&#10;    votes_df.to_csv(csv_buffer, index=False)&#10;    csv_content = csv_buffer.getvalue()&#10;&#10;    st.download_button(&#10;        label=&quot; Download Results as CSV&quot;,&#10;        data=csv_content,&#10;        file_name=&quot;pipeline_comparison_results.csv&quot;,&#10;        mime=&quot;text/csv&quot;&#10;    )&#10;&#10;    # Display detailed results&#10;    with st.expander(&quot;View Detailed Results&quot;):&#10;        st.dataframe(votes_df)&#10;&#10;    # Reset button&#10;    if st.button(&quot; Start New Comparison&quot;):&#10;        st.session_state.results_ready = False&#10;        st.session_state.comparison_results = []&#10;        st.session_state.current_vote_index = 0&#10;        st.session_state.votes = []&#10;        st.session_state.voting_complete = False&#10;        st.rerun()&#10;" />
              <option name="updatedContent" value="import streamlit as st&#10;import pandas as pd&#10;from SourceRetriever import SourceRetriever&#10;from LLM import LLM&#10;from dotenv import dotenv_values&#10;import random&#10;import io&#10;&#10;# --- Page Configuration ---&#10;st.set_page_config(&#10;    page_title=&quot;RAG Pipeline Comparison Tool&quot;,&#10;    page_icon=&quot;&quot;,&#10;    layout=&quot;wide&quot;&#10;)&#10;&#10;# --- Load API Keys ---&#10;@st.cache_data&#10;def load_config():&#10;    try:&#10;        config = dotenv_values(&quot;.env&quot;)&#10;        es_api_key = config.get(&quot;ES_API_KEY&quot;)&#10;        llm_api_key = config.get(&quot;API_KEY&quot;)&#10;        if not es_api_key or not llm_api_key:&#10;            st.error(&#10;                &quot;API keys (ES_API_KEY, API_KEY) not found in your .env file. Please make sure it's configured correctly.&quot;)&#10;            return None, None&#10;        return es_api_key, llm_api_key&#10;    except Exception as e:&#10;        st.error(f&quot;Could not load the .env file. Please make sure it exists in the root directory. Error: {e}&quot;)&#10;        return None, None&#10;&#10;ES_API_KEY, LLM_API_KEY = load_config()&#10;&#10;if not ES_API_KEY or not LLM_API_KEY:&#10;    st.stop()&#10;&#10;# --- Caching the Clients ---&#10;@st.cache_resource&#10;def get_retriever():&#10;    retriever = SourceRetriever(&#10;        host=&quot;https://elasticsearch.bw.webis.de:9200&quot;,&#10;        api_key=ES_API_KEY,&#10;        serps_index=&quot;aql_serps&quot;,&#10;        results_index=&quot;aql_results&quot;&#10;    )&#10;    if not retriever.es_client:&#10;        st.error(&quot;Failed to connect to Elasticsearch. Please check your VPN and API key.&quot;)&#10;        return None&#10;    return retriever&#10;&#10;@st.cache_resource&#10;def get_llm_generator():&#10;    llm = LLM(&#10;        api_key=LLM_API_KEY,&#10;        base_url=&quot;https://api.helmholtz-blablador.fz-juelich.de/v1/&quot;,&#10;        model=&quot;alias-fast&quot;&#10;    )&#10;    if not llm.client:&#10;        st.error(&quot;Failed to initialize the LLM client. Please check your API key.&quot;)&#10;        return None&#10;    return llm&#10;&#10;# --- Test Queries ---&#10;TEST_QUERIES = [&#10;    &quot;What are the health benefits of a Mediterranean diet?&quot;,&#10;    &quot;How does climate change affect coral reefs?&quot;,&#10;    &quot;What is the process of photosynthesis?&quot;,&#10;    &quot;Why is the sky blue?&quot;,&#10;    &quot;What are the main causes of inflation?&quot;,&#10;    &quot;How do vaccines work to prevent diseases?&quot;,&#10;    &quot;What are the effects of exercise on mental health?&quot;,&#10;    &quot;How does artificial intelligence impact job markets?&quot;,&#10;    &quot;What causes earthquakes and how are they measured?&quot;,&#10;    &quot;How do solar panels convert sunlight into electricity?&quot;,&#10;    &quot;What are the benefits and risks of nuclear energy?&quot;,&#10;    &quot;How does the human immune system fight infections?&quot;,&#10;    &quot;What is the role of genetics in determining personality?&quot;,&#10;    &quot;How do hurricanes form and why are they so destructive?&quot;,&#10;    &quot;What are the environmental impacts of fast fashion?&quot;&#10;]&#10;&#10;# --- Pipeline Functions ---&#10;def run_pipeline_1(query, retriever, llm_generator):&#10;    &quot;&quot;&quot;Pipeline 1: Original Query (Direct Context → Filter → Answer)&quot;&quot;&quot;&#10;    try:&#10;        context_df = retriever.get_context(query)&#10;        original_context = context_df.copy() if not context_df.empty else pd.DataFrame()&#10;&#10;        if not context_df.empty:&#10;            # Apply context filtering for Pipeline 1&#10;            filtered_context_df = llm_generator.filter_context(context_df, query)&#10;&#10;            if not filtered_context_df.empty:&#10;                answer = llm_generator.answer_question_from_context(filtered_context_df, query)&#10;                return {&#10;                    'answer': answer or &quot;Could not generate an answer.&quot;,&#10;                    'original_context': original_context,&#10;                    'filtered_context': filtered_context_df&#10;                }&#10;            else:&#10;                return {&#10;                    'answer': &quot;No relevant context found for this query.&quot;,&#10;                    'original_context': original_context,&#10;                    'filtered_context': pd.DataFrame()&#10;                }&#10;        return {&#10;            'answer': &quot;No context retrieved.&quot;,&#10;            'original_context': pd.DataFrame(),&#10;            'filtered_context': pd.DataFrame()&#10;        }&#10;    except Exception as e:&#10;        return {&#10;            'answer': f&quot;Error in Pipeline 1: {str(e)}&quot;,&#10;            'original_context': pd.DataFrame(),&#10;            'filtered_context': pd.DataFrame()&#10;        }&#10;&#10;def run_pipeline_4(query, retriever, llm_generator):&#10;    &quot;&quot;&quot;Pipeline 4: Query Pool (Query Pool → Filtered Context → Direct Answer)&quot;&quot;&quot;&#10;    try:&#10;        query_pool = llm_generator.generate_query_pool(query, 10)&#10;        all_contexts = []&#10;        for q in query_pool:&#10;            pooled_df = retriever.get_context(q)&#10;            if not pooled_df.empty:&#10;                all_contexts.append(pooled_df)&#10;&#10;        if all_contexts:&#10;            full_context_df = pd.concat(all_contexts, ignore_index=True).drop_duplicates(&#10;                subset=['text']).reset_index(drop=True)&#10;            truncated_pool_df = full_context_df.head(100)&#10;            original_context = truncated_pool_df.copy()&#10;&#10;            # Apply context filtering for Pipeline 4&#10;            filtered_context_df = llm_generator.filter_context(truncated_pool_df, query)&#10;&#10;            if not filtered_context_df.empty:&#10;                answer = llm_generator.answer_question_from_context(filtered_context_df, query)&#10;                return {&#10;                    'answer': answer or &quot;Could not generate an answer.&quot;,&#10;                    'original_context': original_context,&#10;                    'filtered_context': filtered_context_df&#10;                }&#10;            else:&#10;                return {&#10;                    'answer': &quot;No relevant context found for this query.&quot;,&#10;                    'original_context': original_context,&#10;                    'filtered_context': pd.DataFrame()&#10;                }&#10;        return {&#10;            'answer': &quot;No context retrieved from query pool.&quot;,&#10;            'original_context': pd.DataFrame(),&#10;            'filtered_context': pd.DataFrame()&#10;        }&#10;    except Exception as e:&#10;        return {&#10;            'answer': f&quot;Error in Pipeline 4: {str(e)}&quot;,&#10;            'original_context': pd.DataFrame(),&#10;            'filtered_context': pd.DataFrame()&#10;        }&#10;&#10;# --- Initialize Session State ---&#10;if 'results_ready' not in st.session_state:&#10;    st.session_state.results_ready = False&#10;if 'comparison_results' not in st.session_state:&#10;    st.session_state.comparison_results = []&#10;if 'current_vote_index' not in st.session_state:&#10;    st.session_state.current_vote_index = 0&#10;if 'votes' not in st.session_state:&#10;    st.session_state.votes = []&#10;if 'voting_complete' not in st.session_state:&#10;    st.session_state.voting_complete = False&#10;&#10;# --- Main App UI ---&#10;st.title(&quot; RAG Pipeline Comparison Tool&quot;)&#10;st.markdown(&#10;    &quot;&quot;&quot;&#10;This application compares Pipeline 1 (Direct Context → Answer) vs Pipeline 4 (Query Pool → Direct Answer).&#10;Click 'Start Comparison' to run 15 test queries through both pipelines and then vote on the results.&#10;&quot;&quot;&quot;&#10;)&#10;&#10;retriever = get_retriever()&#10;llm_generator = get_llm_generator()&#10;&#10;if not retriever or not llm_generator:&#10;    st.warning(&quot;One or more services could not be initialized. The app cannot proceed.&quot;)&#10;    st.stop()&#10;&#10;# --- Run Comparison ---&#10;if not st.session_state.results_ready:&#10;    if st.button(&quot;Start Comparison&quot;, type=&quot;primary&quot;):&#10;        st.session_state.comparison_results = []&#10;&#10;        # Progress bar&#10;        progress_bar = st.progress(0)&#10;        status_text = st.empty()&#10;&#10;        for i, query in enumerate(TEST_QUERIES):&#10;            status_text.text(f&quot;Processing query {i+1}/15: {query}&quot;)&#10;&#10;            # Run both pipelines&#10;            pipeline1_result = run_pipeline_1(query, retriever, llm_generator)&#10;            pipeline4_result = run_pipeline_4(query, retriever, llm_generator)&#10;&#10;            # Randomly assign which pipeline goes to left/right&#10;            if random.choice([True, False]):&#10;                left_result = (&quot;Pipeline 1&quot;, pipeline1_result)&#10;                right_result = (&quot;Pipeline 4&quot;, pipeline4_result)&#10;            else:&#10;                left_result = (&quot;Pipeline 4&quot;, pipeline4_result)&#10;                right_result = (&quot;Pipeline 1&quot;, pipeline1_result)&#10;&#10;            st.session_state.comparison_results.append({&#10;                'query': query,&#10;                'left': left_result,&#10;                'right': right_result,&#10;                'pipeline1_answer': pipeline1_result['answer'],&#10;                'pipeline4_answer': pipeline4_result['answer']&#10;            })&#10;&#10;            progress_bar.progress((i + 1) / len(TEST_QUERIES))&#10;&#10;        status_text.text(&quot;✅ All queries processed! Ready for voting.&quot;)&#10;        st.session_state.results_ready = True&#10;        st.rerun()&#10;&#10;# --- Voting Interface ---&#10;elif st.session_state.results_ready and not st.session_state.voting_complete:&#10;    st.header(&quot;️ Vote for the Better Answer&quot;)&#10;&#10;    current_idx = st.session_state.current_vote_index&#10;    if current_idx &lt; len(st.session_state.comparison_results):&#10;        result = st.session_state.comparison_results[current_idx]&#10;&#10;        # Progress indicator&#10;        st.progress((current_idx + 1) / len(st.session_state.comparison_results))&#10;        st.text(f&quot;Question {current_idx + 1} of {len(st.session_state.comparison_results)}&quot;)&#10;&#10;        # Display query&#10;        st.subheader(&quot;Query:&quot;)&#10;        st.info(result['query'])&#10;&#10;        # Display answers side by side&#10;        col1, col2 = st.columns(2)&#10;&#10;        with col1:&#10;            st.subheader(&quot;Answer A&quot;)&#10;            st.write(result['left'][1]['answer'])&#10;&#10;        with col2:&#10;            st.subheader(&quot;Answer B&quot;)&#10;            st.write(result['right'][1]['answer'])&#10;&#10;        # Context Viewing Dropdown&#10;        st.markdown(&quot;---&quot;)&#10;        st.subheader(&quot; Context Inspection&quot;)&#10;&#10;        # Get pipeline results for context display&#10;        pipeline1_result = None&#10;        pipeline4_result = None&#10;&#10;        # Determine which pipeline is which&#10;        for name, result_data in [result['left'], result['right']]:&#10;            if name == &quot;Pipeline 1&quot;:&#10;                pipeline1_result = result_data&#10;            elif name == &quot;Pipeline 4&quot;:&#10;                pipeline4_result = result_data&#10;&#10;        # Create context view options&#10;        context_options = []&#10;        context_data = {}&#10;&#10;        if pipeline1_result is not None:&#10;            if not pipeline1_result['original_context'].empty:&#10;                context_options.append(&quot;Pipeline 1 - Original Context&quot;)&#10;                context_data[&quot;Pipeline 1 - Original Context&quot;] = pipeline1_result['original_context']&#10;&#10;            if not pipeline1_result['filtered_context'].empty:&#10;                context_options.append(&quot;Pipeline 1 - Filtered Context&quot;)&#10;                context_data[&quot;Pipeline 1 - Filtered Context&quot;] = pipeline1_result['filtered_context']&#10;&#10;        if pipeline4_result is not None:&#10;            if not pipeline4_result['original_context'].empty:&#10;                context_options.append(&quot;Pipeline 4 - Original Context&quot;)&#10;                context_data[&quot;Pipeline 4 - Original Context&quot;] = pipeline4_result['original_context']&#10;&#10;            if not pipeline4_result['filtered_context'].empty:&#10;                context_options.append(&quot;Pipeline 4 - Filtered Context&quot;)&#10;                context_data[&quot;Pipeline 4 - Filtered Context&quot;] = pipeline4_result['filtered_context']&#10;&#10;        if context_options:&#10;            selected_context = st.selectbox(&#10;                &quot;Select context to view:&quot;,&#10;                options=[&quot;None&quot;] + context_options,&#10;                index=0&#10;            )&#10;&#10;            if selected_context != &quot;None&quot; and selected_context in context_data:&#10;                selected_df = context_data[selected_context]&#10;&#10;                # Display context statistics&#10;                col1, col2 = st.columns(2)&#10;                with col1:&#10;                    st.metric(&quot;Number of snippets&quot;, len(selected_df))&#10;                with col2:&#10;                    if &quot;Pipeline 1&quot; in selected_context and pipeline1_result is not None:&#10;                        original_count = len(pipeline1_result['original_context'])&#10;                        filtered_count = len(pipeline1_result['filtered_context'])&#10;                        if &quot;Filtered&quot; in selected_context and original_count &gt; 0:&#10;                            retention_rate = (filtered_count / original_count) * 100&#10;                            st.metric(&quot;Retention rate&quot;, f&quot;{retention_rate:.1f}%&quot;)&#10;                    elif &quot;Pipeline 4&quot; in selected_context and pipeline4_result is not None:&#10;                        original_count = len(pipeline4_result['original_context'])&#10;                        filtered_count = len(pipeline4_result['filtered_context'])&#10;                        if &quot;Filtered&quot; in selected_context and original_count &gt; 0:&#10;                            retention_rate = (filtered_count / original_count) * 100&#10;                            st.metric(&quot;Retention rate&quot;, f&quot;{retention_rate:.1f}%&quot;)&#10;&#10;                # Display context snippets&#10;                with st.expander(f&quot;View {selected_context} snippets&quot;, expanded=True):&#10;                    for idx, row in selected_df.iterrows():&#10;                        st.markdown(f&quot;**Snippet {idx + 1}:**&quot;)&#10;                        st.text(row['text'])&#10;                        st.markdown(&quot;---&quot;)&#10;        else:&#10;            st.info(&quot;No context available for this query.&quot;)&#10;&#10;        # Voting buttons&#10;        st.markdown(&quot;---&quot;)&#10;        col1, col2, col3 = st.columns(3)&#10;&#10;        with col1:&#10;            if st.button(&quot; Answer A is Better&quot;, use_container_width=True):&#10;                winner = result['left'][0]  # Pipeline name&#10;                st.session_state.votes.append({&#10;                    'query': result['query'],&#10;                    'output_1': result['pipeline1_answer'],&#10;                    'output_2': result['pipeline4_answer'],&#10;                    'winner': winner&#10;                })&#10;                st.session_state.current_vote_index += 1&#10;                st.rerun()&#10;&#10;        with col2:&#10;            if st.button(&quot; Don't Care&quot;, use_container_width=True):&#10;                st.session_state.votes.append({&#10;                    'query': result['query'],&#10;                    'output_1': result['pipeline1_answer'],&#10;                    'output_2': result['pipeline4_answer'],&#10;                    'winner': 'Don\'t Care'&#10;                })&#10;                st.session_state.current_vote_index += 1&#10;                st.rerun()&#10;&#10;        with col3:&#10;            if st.button(&quot; Answer B is Better&quot;, use_container_width=True):&#10;                winner = result['right'][0]  # Pipeline name&#10;                st.session_state.votes.append({&#10;                    'query': result['query'],&#10;                    'output_1': result['pipeline1_answer'],&#10;                    'output_2': result['pipeline4_answer'],&#10;                    'winner': winner&#10;                })&#10;                st.session_state.current_vote_index += 1&#10;                st.rerun()&#10;&#10;    else:&#10;        st.session_state.voting_complete = True&#10;        st.rerun()&#10;&#10;# --- Results and Export ---&#10;elif st.session_state.voting_complete:&#10;    st.header(&quot; Voting Complete!&quot;)&#10;&#10;    # Display results summary&#10;    votes_df = pd.DataFrame(st.session_state.votes)&#10;&#10;    st.subheader(&quot;Results Summary&quot;)&#10;    pipeline1_wins = len(votes_df[votes_df['winner'] == 'Pipeline 1'])&#10;    pipeline4_wins = len(votes_df[votes_df['winner'] == 'Pipeline 4'])&#10;    dont_care = len(votes_df[votes_df['winner'] == 'Don\'t Care'])&#10;&#10;    col1, col2, col3 = st.columns(3)&#10;    with col1:&#10;        st.metric(&quot;Pipeline 1 Wins&quot;, pipeline1_wins)&#10;    with col2:&#10;        st.metric(&quot;Pipeline 4 Wins&quot;, pipeline4_wins)&#10;    with col3:&#10;        st.metric(&quot;Don't Care&quot;, dont_care)&#10;&#10;    # Export functionality&#10;    st.subheader(&quot;Export Results&quot;)&#10;&#10;    # Create CSV content&#10;    csv_buffer = io.StringIO()&#10;    votes_df.to_csv(csv_buffer, index=False)&#10;    csv_content = csv_buffer.getvalue()&#10;&#10;    st.download_button(&#10;        label=&quot; Download Results as CSV&quot;,&#10;        data=csv_content,&#10;        file_name=&quot;pipeline_comparison_results.csv&quot;,&#10;        mime=&quot;text/csv&quot;&#10;    )&#10;&#10;    # Display detailed results&#10;    with st.expander(&quot;View Detailed Results&quot;):&#10;        st.dataframe(votes_df)&#10;&#10;    # Reset button&#10;    if st.button(&quot; Start New Comparison&quot;):&#10;        st.session_state.results_ready = False&#10;        st.session_state.comparison_results = []&#10;        st.session_state.current_vote_index = 0&#10;        st.session_state.votes = []&#10;        st.session_state.voting_complete = False&#10;        st.rerun()" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>